{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sublists from GAIA DR2 Cantat-Gaudin paper\n",
    "\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "input_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/members.dat.gz\"\n",
    "output_file_path = 'NGC2451B - Cantat-Gaudin.csv'\n",
    "\n",
    "with gzip.open(input_file_path, 'rt') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')  \n",
    "    \n",
    "    with open(output_file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        for row in reader:\n",
    "            if 'NGC_2451B' in ' '.join(row):\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "input_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/table1.dat\"\n",
    "output_file_path = 'table1.csv'\n",
    "\n",
    "with open(input_file_path, 'rt') as infile:\n",
    "    reader = csv.reader(infile, delimiter='|')\n",
    "\n",
    "    with open(output_file_path, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "\n",
    "        for row in reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "\n",
    "input_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/members.dat.gz\"\n",
    "output_file_path = 'fullCGmembers.csv'\n",
    "\n",
    "with gzip.open(input_file_path, 'rt') as infile:\n",
    "    reader = csv.reader(infile, delimiter='|')\n",
    "\n",
    "    with open(output_file_path, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "\n",
    "        for row in reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install astroquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.mast import Catalogs\n",
    "import csv\n",
    "\n",
    "def gaia_to_tic(gaia_id):\n",
    "    try:\n",
    "        result = Catalogs.query_criteria(catalog=\"Tic\", GAIA=gaia_id)\n",
    "        if len(result) > 0:\n",
    "            return result['ID'][0]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while querying GAIA ID {gaia_id}: {e}\")\n",
    "    return None\n",
    "\n",
    "input_csv = \"/Users/tilakpatel/Downloads/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/NGC2451B - Cantat-Gaudin.csv\"\n",
    "output_csv = 'output_with_tic_ids.csv'\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "with open(input_csv, mode='r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=' ', skipinitialspace=True)\n",
    "\n",
    "    for row in reader:\n",
    "        print(f\"Raw row: {row}\")\n",
    "\n",
    "        filtered_row = list(filter(None, row))\n",
    "        \n",
    "        print(f\"Filtered row: {filtered_row}\")\n",
    "\n",
    "        if len(filtered_row) < 3:\n",
    "            print(f\"Skipping row with insufficient data fields: {filtered_row}\")\n",
    "            continue\n",
    "\n",
    "        gaia_id = filtered_row[2]\n",
    "        print(f\"Processing GAIA ID: {gaia_id}\")\n",
    "\n",
    "        tic_id = gaia_to_tic(gaia_id)\n",
    "        filtered_row.append(tic_id)\n",
    "        output_rows.append(filtered_row)\n",
    "\n",
    "if output_rows:\n",
    "    with open(output_csv, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=' ', skipinitialspace=True)\n",
    "        writer.writerows(output_rows)\n",
    "    print(f\"Output with TIC IDs saved to {output_csv}\")\n",
    "else:\n",
    "    print(\"No output rows were generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"/Users/tilakpatel/Downloads/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Praesepe - Cantat-Gaudin.csv\")\n",
    "\n",
    "column_data = df.iloc[:, 2]\n",
    "\n",
    "column_array = np.array(column_data)\n",
    "\n",
    "print(column_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting from GAIA DR2 to TIC\n",
    "from astroquery.mast import Observations, Catalogs\n",
    "import numpy as np\n",
    "import lightkurve as lk\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Collinder 359 - Cantat-Gaudin.csv', delim_whitespace=True)\n",
    "\n",
    "column_data = df.iloc[:, 2].astype(str)\n",
    "gaia_ids = np.array(column_data)\n",
    "\n",
    "result = Catalogs.query_criteria(catalog=\"Tic\", GAIA=gaia_ids).to_pandas()\n",
    "print(\"Data\", result)\n",
    "print(len(gaia_ids))\n",
    "\n",
    "tics = result.iloc[:, 0]\n",
    "print(tics)\n",
    "\n",
    "tics_df = pd.DataFrame([tics]).transpose()\n",
    "\n",
    "tics_df.to_csv(\"/Users/tilakpatel/Downloads/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Collinder359Tics.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tics_df.to_csv(\"/Users/tilakpatel/Downloads/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Pleiadestics2.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.mast import Catalogs\n",
    "import numpy as np\n",
    "column_data = [(65266494828710400)]\n",
    "print(column_data)\n",
    "gaia_ids = np.array(column_data)\n",
    "print(gaia_ids)\n",
    "result = Catalogs.query_criteria(catalog=\"Tic\", GAIA=gaia_ids)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.mast import Catalogs\n",
    "import numpy as np\n",
    "column_data = [(66490977124308352)]\n",
    "print(column_data)\n",
    "gaia_ids = np.array(column_data)\n",
    "print(gaia_ids)\n",
    "result = Catalogs.query_criteria(catalog=\"Tic\", GAIA=gaia_ids)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1: Convert GAIADR2 to TIC\n",
    "\n",
    "from astroquery.mast import Catalogs\n",
    "import pandas as pd\n",
    "\n",
    "cluster_names = [\"NGC2451B\"]\n",
    "base_directory = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/\"\n",
    "\n",
    "for cluster_name in cluster_names:\n",
    "    file_name = f\"{cluster_name} - Cantat-Gaudin.csv\"\n",
    "    file_path = f\"{base_directory}{file_name}\"\n",
    "    print(f\"\\nLoading the file: {file_path}\")\n",
    "    df = pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "    print(\"Extracting GAIA IDs...\")\n",
    "    gaia_ids = df.iloc[:, 2].values\n",
    "\n",
    "    print(\"Querying TIC IDs for the GAIA IDs...\")\n",
    "    result = Catalogs.query_criteria(catalog=\"Tic\", GAIA=gaia_ids).to_pandas()\n",
    "\n",
    "    df[df.columns[2]] = df[df.columns[2]].astype(str)\n",
    "    result['GAIA'] = result['GAIA'].astype(str)\n",
    "\n",
    "    print(\"Selecting the first TIC ID for each GAIA ID in case of duplicates...\")\n",
    "    result = result.groupby('GAIA').first().reset_index()\n",
    "\n",
    "    print(\"Merging TIC IDs with the original DataFrame...\")\n",
    "    df = df.merge(result[['ID', 'GAIA']], how='left', left_on=df.columns[2], right_on='GAIA')\n",
    "\n",
    "    df.rename(columns={'ID': 'TIC ID'}, inplace=True)\n",
    "\n",
    "    print(\"TIC IDs added next to corresponding GAIA IDs.\")\n",
    "\n",
    "    output_file = f\"{base_directory}{cluster_name}_with_TIC.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"File saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory = \"/Users/tilakpatel/Downloads/Honours Project/120s Data/\"\n",
    "\n",
    "output_file = os.path.join(directory, 'combined_data.csv')\n",
    "\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for i in range(1, 78):  # 1 through 77\n",
    "        file_name = f\"all_targets_S{str(i).zfill(3)}_v1.csv\"\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r') as infile:\n",
    "                if i != 1:\n",
    "                    next(infile)\n",
    "                \n",
    "                for line in infile:\n",
    "                    outfile.write(line)\n",
    "        else:\n",
    "            print(f\"File not found: {file_name}\")\n",
    "\n",
    "print(f\"All data combined into {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path_1 = '/Users/tilakpatel/Downloads/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AlphaPerseiTics.csv'\n",
    "file_path_2 = '/Users/tilakpatel/Downloads/Honours Project/120s Data/120s Data - All Sectors.csv'\n",
    "\n",
    "df1 = pd.read_csv(file_path_1, header=None, names=['numbers'])\n",
    "df2 = pd.read_csv(file_path_2, skiprows=5, usecols=[0], header=None, names=['numbers'])\n",
    "\n",
    "print(df1)\n",
    "print(df2)\n",
    "\n",
    "numbers_in_second_file = set(df2['numbers'])\n",
    "\n",
    "matching_count = df1['numbers'].apply(lambda x: x in numbers_in_second_file).sum()\n",
    "\n",
    "total_numbers = len(df1)\n",
    "fraction = matching_count / total_numbers if total_numbers > 0 else 0\n",
    "\n",
    "print(f\"Fraction of numbers that appear in both files: {fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory_path = \"/Users/tilakpatel/Downloads/Honours Project/120s Data/\"\n",
    "\n",
    "reference_df = pd.read_csv('/Users/tilakpatel/Downloads/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/SouthernPleiadesTics.csv')\n",
    "if reference_df.shape[1] < 1:\n",
    "    raise ValueError(\"The reference file does not have any columns.\")\n",
    "\n",
    "reference_numbers = reference_df.iloc[:, 0].tolist()\n",
    "\n",
    "tallies = {f'all_targets_S{i:03d}_v1.csv': 0 for i in range(1, 79)}\n",
    "found_numbers = set()\n",
    "\n",
    "for number in reference_numbers:\n",
    "    for i in range(1, 79):\n",
    "        file_name = f'all_targets_S{i:03d}_v1.csv'\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        target_df = pd.read_csv(file_path, skiprows=5)\n",
    "\n",
    "        if target_df.shape[1] > 0 and number in target_df.iloc[:, 0].values:\n",
    "            tallies[file_name] += 1\n",
    "            found_numbers.add(number)\n",
    "\n",
    "total_numbers = len(reference_numbers)\n",
    "fraction_found = len(found_numbers) / total_numbers\n",
    "\n",
    "print(f\"Fraction of numbers found in any of the target files: {fraction_found:.4f} ({len(found_numbers)}/{total_numbers})\")\n",
    "\n",
    "print(\"\\nTallies for each file:\")\n",
    "for file, count in tallies.items():\n",
    "    print(f'{file}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"Loading the TIC ID file...\")\n",
    "tic_df = pd.read_csv('/Users/tilakpatel/Downloads/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Alpha Persei.csv')\n",
    "\n",
    "if 'TIC' not in tic_df.columns:\n",
    "    raise ValueError(\"The file does not have a 'TIC' column.\")\n",
    "\n",
    "tic_df['Sector'] = None\n",
    "\n",
    "directory_path = \"/Users/tilakpatel/Downloads/Honours Project/120s Data/\"\n",
    "\n",
    "for index, row in tic_df.iterrows():\n",
    "    tic_id = row['TIC']\n",
    "    print(f\"Processing TIC ID: {tic_id}\")\n",
    "    \n",
    "    for i in range(1, 79):\n",
    "        file_name = f'all_targets_S{i:03d}_v1.csv'\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        print(f\"Checking against file: {file_name}\")\n",
    "        \n",
    "        target_df = pd.read_csv(file_path, skiprows=5)\n",
    "\n",
    "        if target_df.shape[1] > 0:\n",
    "            if tic_id in target_df.iloc[:, 0].values:\n",
    "                tic_df.at[index, 'Sector'] = i\n",
    "                print(f\"Match found in file: {file_name}\")\n",
    "                break\n",
    "\n",
    "print(\"Saving the updated file...\")\n",
    "tic_df.to_csv('/Users/tilakpatel/Downloads/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/update.csv', index=False)\n",
    "print(\"Processing complete. The updated file has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2: Add sector column for each TIC ID\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "clusters = ['Mamajek1_with_TIC']\n",
    "base_directory = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/'\n",
    "\n",
    "directory_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/120s Data/\"\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_file_path = os.path.join(base_directory, f'{cluster}.csv')\n",
    "    print(f\"Loading the TIC ID file for {cluster}...\")\n",
    "\n",
    "    tic_df = pd.read_csv(cluster_file_path)\n",
    "\n",
    "    if 'TIC' not in tic_df.columns:\n",
    "        raise ValueError(f\"The file for {cluster} does not have a 'TIC' column.\")\n",
    "\n",
    "    tic_df['Sector'] = None\n",
    "\n",
    "    for index, row in tic_df.iterrows():\n",
    "        tic_id = row['TIC']\n",
    "        print(f\"Processing TIC ID: {tic_id} in {cluster}\")\n",
    "\n",
    "        for i in range(1, 79):\n",
    "            file_name = f'all_targets_S{i:03d}_v1.csv'\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            print(f\"Checking against file: {file_name}\")\n",
    "\n",
    "            target_df = pd.read_csv(file_path, skiprows=5)\n",
    "\n",
    "            if target_df.shape[1] > 0:\n",
    "                if tic_id in target_df.iloc[:, 0].values:\n",
    "                    tic_df.at[index, 'Sector'] = i\n",
    "                    print(f\"Match found in file: {file_name}\")\n",
    "                    break\n",
    "\n",
    "    updated_file_path = os.path.join(base_directory, f'updated ({cluster}).csv')\n",
    "    print(f\"Saving the updated file for {cluster}...\")\n",
    "    tic_df.to_csv(updated_file_path, index=False)\n",
    "    print(f\"Processing complete for {cluster}. The updated file has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3: If Sector entry exists, add a 1 in the 120s column\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "files = ['Mamajek1new.csv']\n",
    "base_directory = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/'\n",
    "\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(base_directory, file_name)\n",
    "    print(f\"Processing {file_name}...\")\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    if 'Sector' not in df.columns:\n",
    "        print(f\"No 'Sector' column found in {file_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    df['120s Data'] = df['Sector'].apply(lambda x: 0 if pd.isnull(x) or x == '' else 1)\n",
    "\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Updated {file_name} has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5: Create HRD\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "file_path = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/NGC3532.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['Bp-Rp'] = pd.to_numeric(df['Bp-Rp'], errors='coerce')\n",
    "df['AbsMag'] = pd.to_numeric(df['AbsMag'], errors='coerce')\n",
    "df.dropna(subset=['Bp-Rp', 'AbsMag'], inplace=True)\n",
    "\n",
    "if 'Bp-Rp' not in df.columns or 'AbsMag' not in df.columns or '120s Data' not in df.columns:\n",
    "    raise ValueError(\"The required columns are not found in the CSV file.\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "green_points = df[df['120s Data'] == 1]\n",
    "red_points = df[df['120s Data'] == 0]\n",
    "\n",
    "plt.scatter(green_points['Bp-Rp'], green_points['AbsMag'], color='green', label='With 120s Data', alpha=0.5)\n",
    "plt.scatter(red_points['Bp-Rp'], red_points['AbsMag'], color='red', label='Without 120s Data', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Bp-Rp')\n",
    "plt.ylabel('AbsMag')\n",
    "plt.ylim(0, 8)\n",
    "plt.xlim(-0.15, 1.5)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "plt.title(file_name)\n",
    "\n",
    "plt.savefig(os.path.splitext(file_path)[0] + '_Colour-Magnitude_Diagram.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "file_path = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Castor.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['(B-V)'] = pd.to_numeric(df['(B-V)'], errors='coerce')\n",
    "df['M_v'] = pd.to_numeric(df['M_v'], errors='coerce')\n",
    "df.dropna(subset=['(B-V)', 'M_v'], inplace=True)\n",
    "\n",
    "if '(B-V)' not in df.columns or 'M_v' not in df.columns:\n",
    "    raise ValueError(\"The required columns are not found in the CSV file.\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(df['(B-V)'], df['M_v'], color='blue', alpha=0.5)\n",
    "\n",
    "plt.xlabel('(B-V)')\n",
    "plt.ylabel('M_v')\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "plt.title(file_name)\n",
    "\n",
    "plt.savefig(os.path.splitext(file_path)[0] + '_Colour-Magnitude_Diagram.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "file_path = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/ClustersOfInterestCombined.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['Bp-Rp'] = pd.to_numeric(df['Bp-Rp'], errors='coerce')\n",
    "df['AbsMag'] = pd.to_numeric(df['AbsMag'], errors='coerce')\n",
    "df['Cluster Age (MYr)'] = pd.to_numeric(df['Cluster Age (MYr)'], errors='coerce')\n",
    "df.dropna(subset=['Bp-Rp', 'AbsMag', 'Cluster Age (MYr)'], inplace=True)\n",
    "\n",
    "df = df.sort_values('Cluster Age (MYr)')\n",
    "\n",
    "required_columns = ['Bp-Rp', 'AbsMag', 'Cluster Age (MYr)']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"The required column {col} is not found in the CSV file.\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "norm = plt.Normalize(df['Cluster Age (MYr)'].min(), df['Cluster Age (MYr)'].max())\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "sc = plt.scatter(df['Bp-Rp'], df['AbsMag'], c=df['Cluster Age (MYr)'], cmap=cmap, norm=norm, alpha=0.5)\n",
    "\n",
    "plt.xlabel('Bp-Rp', fontsize=20)\n",
    "plt.ylabel('AbsMag', fontsize=20)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylim(4, 2)\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label('Cluster Age (MYr)')\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "plt.title(file_name)\n",
    "\n",
    "plt.savefig(os.path.splitext(file_path)[0] + '_Colour-Magnitude_Diagram_Distance_zoomed2.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/tilakpatel/Downloads/Honours Project/120s Data/all_targets_S001_v1.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, skiprows=5)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from astroquery.gaia import Gaia\n",
    "\n",
    "df = pd.read_csv(\"/Users/tilakpatel/Downloads/Honours Project/membership1.csv\")\n",
    "\n",
    "hyades_df = df[df['Cluster'].str.lower() == 'hyades']\n",
    "\n",
    "hyades_df['GaiaDR1'] = hyades_df['GaiaDR1'].astype(str)\n",
    "\n",
    "gmag_values = []\n",
    "\n",
    "for gaia_id in hyades_df['GaiaDR1']:\n",
    "    job = Gaia.launch_job_async(f\"SELECT phot_g_mean_mag FROM gaiadr1.gaia_source WHERE source_id = {gaia_id}\")\n",
    "    results = job.get_results()\n",
    "    \n",
    "    if not results or results['phot_g_mean_mag'].mask[0]:\n",
    "        gmag_values.append(None)\n",
    "    else:\n",
    "        gmag_values.append(results['phot_g_mean_mag'][0])\n",
    "\n",
    "hyades_df['Gmag'] = gmag_values\n",
    "\n",
    "hyades_df.to_csv(\"/Users/tilakpatel/Downloads/Honours Project/newmembership.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Individual GAIA DR2 -> TIC\n",
    "from astroquery.mast import Catalogs\n",
    "\n",
    "gaia_id = '5240284894897063424'\n",
    "\n",
    "result = Catalogs.query_criteria(catalog=\"Tic\", GAIA=gaia_id).to_pandas()\n",
    "\n",
    "tic_id = result.iloc[0]['ID'] if not result.empty else None\n",
    "\n",
    "print(f\"The TIC ID for GAIA DR2 ID {gaia_id} is: {tic_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 4: Convert Gmag to Abs Mag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Mamajek1new.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['AbsMag'] = df['Gmag'] - 5*np.log10(97.069) + 5\n",
    "\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas astroquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.simbad import Simbad\n",
    "import pandas as pd\n",
    "\n",
    "def get_gaia_ids(other_id):\n",
    "    result_table = Simbad.query_objectids(other_id)\n",
    "    \n",
    "    gaia_dr3_id = None\n",
    "    gaia_dr2_id = None\n",
    "    \n",
    "    if result_table is not None and 'ID' in result_table.colnames:\n",
    "        identifiers = result_table['ID']\n",
    "        gaia_dr3_id = next((id.split(\" \")[-1] for id in identifiers if \"Gaia DR3\" in id), None)\n",
    "        gaia_dr2_id = next((id.split(\" \")[-1] for id in identifiers if \"Gaia DR2\" in id), None)\n",
    "    else:\n",
    "        print(f\"Error: Unable to retrieve Gaia IDs for {other_id}\")\n",
    "    \n",
    "    return gaia_dr3_id, gaia_dr2_id\n",
    "\n",
    "def process_csv(file_path, output_file_path):\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    \n",
    "    df[['Gaia_DR3_ID', 'Gaia_DR2_ID']] = df[0].apply(lambda x: pd.Series(get_gaia_ids(x)))\n",
    "    \n",
    "    df.to_csv(output_file_path, index=False)\n",
    "    return df\n",
    "\n",
    "input_file_path = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/Guerrerez/Clusters of Interest/cha2.csv'\n",
    "output_file_path = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/Guerrerez/Clusters of Interest/gammaGAIA.csv'\n",
    "result_df = process_csv(input_file_path, output_file_path)\n",
    "print(\"Processing complete. Results saved to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.simbad import Simbad\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_gaia_ids(other_id):\n",
    "    result_table = Simbad.query_objectids(other_id)\n",
    "    \n",
    "    gaia_dr3_id = None\n",
    "    gaia_dr2_id = None\n",
    "    \n",
    "    if result_table is not None and 'ID' in result_table.colnames:\n",
    "        identifiers = result_table['ID']\n",
    "        gaia_dr3_id = next((id.split(\" \")[-1] for id in identifiers if \"Gaia DR3\" in id), None)\n",
    "        gaia_dr2_id = next((id.split(\" \")[-1] for id in identifiers if \"Gaia DR2\" in id), None)\n",
    "    else:\n",
    "        print(f\"Error: Unable to retrieve Gaia IDs for {other_id}\")\n",
    "    \n",
    "    return gaia_dr3_id, gaia_dr2_id\n",
    "\n",
    "def process_csv(file_path, output_file_path):\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    \n",
    "    df[['Gaia_DR3_ID', 'Gaia_DR2_ID']] = df[0].apply(lambda x: pd.Series(get_gaia_ids(x)))\n",
    "    \n",
    "    df.to_csv(output_file_path, index=False)\n",
    "    return df\n",
    "\n",
    "base_folder = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/Guerrerez/Clusters of Interest/'\n",
    "files = ['ic46652.csv', 'ngc25162.csv', 'ngc25472.csv', 'ngc66332.csv', 'rho2.csv']\n",
    "\n",
    "for file_name in files:\n",
    "    input_file_path = os.path.join(base_folder, file_name)\n",
    "    output_file_path = os.path.join(base_folder, file_name.replace('.csv', 'GAIA.csv'))\n",
    "    print(f\"Processing {file_name}...\")\n",
    "    result_df = process_csv(input_file_path, output_file_path)\n",
    "    print(f\"Processing complete. Results saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from astroquery.gaia import Gaia\n",
    "import os\n",
    "\n",
    "def query_gaia(id_column, id_prefix, table_name):\n",
    "    query_results = []\n",
    "    print(f\"Starting to query Gaia with {len(id_column)} IDs using {id_prefix}...\")\n",
    "    for id in id_column:\n",
    "        print(f\"Querying Gaia for ID: {id}\")\n",
    "        job = Gaia.launch_job(f\"SELECT * FROM {table_name} WHERE {id_prefix} = {id}\")\n",
    "        r = job.get_results()\n",
    "        if len(r) > 0:\n",
    "            query_results.append(r.to_pandas())\n",
    "            print(f\"Data retrieved for ID: {id}\")\n",
    "        else:\n",
    "            query_results.append(pd.DataFrame())\n",
    "            print(f\"No data found for ID: {id}\")\n",
    "    return pd.concat(query_results, ignore_index=True)\n",
    "\n",
    "def process_gaia_data(file_path, output_file_path):\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    df = pd.read_csv(file_path, dtype={'Gaia_DR3_ID': 'Int64', 'Gaia_DR2_ID': 'Int64'})\n",
    "    print(\"First few rows of the data:\")\n",
    "    print(df.head())\n",
    "    print(\"Data types of the columns:\")\n",
    "    print(df.dtypes)\n",
    "    gaia_data = pd.DataFrame()\n",
    "\n",
    "    if not df['Gaia_DR3_ID'].isna().all():\n",
    "        print(\"Querying Gaia DR3...\")\n",
    "        gaia_data = query_gaia(df['Gaia_DR3_ID'].dropna(), 'source_id', 'gaiaedr3.gaia_source')\n",
    "    elif not df['Gaia_DR2_ID'].isna().all():\n",
    "        print(\"Gaia DR3 data not found, querying Gaia DR2...\")\n",
    "        gaia_data = query_gaia(df['Gaia_DR2_ID'].dropna(), 'source_id', 'gaiadr2.gaia_source')\n",
    "    else:\n",
    "        print(\"No valid Gaia IDs found.\")\n",
    "\n",
    "    gaia_data.to_csv(output_file_path, index=False)\n",
    "    print(f\"Data retrieval complete. Results saved to: {output_file_path}\")\n",
    "    return gaia_data\n",
    "\n",
    "def process_multiple_files(file_list, base_folder):\n",
    "    for file_name in file_list:\n",
    "        input_file_path = os.path.join(base_folder, file_name)\n",
    "        output_file_name = file_name.replace('.csv', 'complete.csv')\n",
    "        output_file_path = os.path.join(base_folder, output_file_name)\n",
    "        result_df = process_gaia_data(input_file_path, output_file_path)\n",
    "\n",
    "base_folder = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/Guerrerez/Clusters of Interest'\n",
    "file_list = ['ic46652GAIA.csv', 'ngc25162GAIA.csv', 'ngc25472GAIA.csv', 'ngc66332GAIA.csv', 'rho2GAIA.csv']\n",
    "\n",
    "process_multiple_files(file_list, base_folder)\n",
    "\n",
    "input_file_path = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/Guerrerez/Clusters of Interest/chaGAIA.csv'\n",
    "output_file_path = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/Guerrerez/Clusters of Interest/chacomplete.csv'\n",
    "\n",
    "result_df = process_gaia_data(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from astroquery.gaia import Gaia\n",
    "\n",
    "def test_query():\n",
    "    job = Gaia.launch_job(\"SELECT * FROM gaiaedr3.gaia_source WHERE source_id = 5201098197369663488\")\n",
    "    r = job.get_results()\n",
    "    print(r)\n",
    "\n",
    "test_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut membership list between 0 and 0.7 Bp-Rp and -2 and 6 AbsMag\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def filter_and_save_csv(input_file_path, output_file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    df['Bp-Rp'] = pd.to_numeric(df['Bp-Rp'], errors='coerce')\n",
    "    df['AbsMag'] = pd.to_numeric(df['AbsMag'], errors='coerce')\n",
    "    \n",
    "    filtered_df = df[(df['Bp-Rp'] >= 0) & (df['Bp-Rp'] <= 0.7) & (df['AbsMag'] >= -2) & (df['AbsMag'] <= 6)]\n",
    "    \n",
    "    filtered_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"Filtered data saved to {output_file_path}\")\n",
    "\n",
    "input_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/ClustersOfInterestCombined.csv\"\n",
    "output_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/ClustersOfInterestCut.csv\"\n",
    "\n",
    "filter_and_save_csv(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count how many stars have 120s data \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def sum_and_count_stars(file_path, data_column, cluster_column):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    df[data_column] = pd.to_numeric(df[data_column], errors='coerce')\n",
    "    \n",
    "    total_sum = df[data_column].sum()\n",
    "    print(f\"The total sum of the '{data_column}' column is: {total_sum}\")\n",
    "    \n",
    "    cluster_counts = df[cluster_column].value_counts()\n",
    "    \n",
    "    print(\"\\nNumber of stars in each cluster:\")\n",
    "    for cluster, count in cluster_counts.items():\n",
    "        print(f\"{cluster}: {count}\")\n",
    "\n",
    "file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/ClustersOfInterestCut.csv\"\n",
    "\n",
    "sum_and_count_stars(file_path, '120s Data', 'Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIGHTCURVES\n",
    "\n",
    "!pip install lightkurve\n",
    "!pip install astroquery\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.timeseries import LombScargle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = lk.search_lightcurve(star,mission='TESS',author='SPOC',exptime=120)\n",
    "search\n",
    "\n",
    "lc_collection = search.download_all()\n",
    "lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "lc.plot()\n",
    "time=lc.time.value\n",
    "flux=lc.flux.value\n",
    "\n",
    "nan_mask = ~np.isnan(time) & ~np.isnan(flux)\n",
    "time = time[nan_mask]\n",
    "flux = flux[nan_mask]\n",
    "\n",
    "def calc_lomb_scargle(t,y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin) # frequency resolution\n",
    "    fmin = 0\n",
    "    fmax = 100 # highest frequency (c/d)\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    sc = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4./len(t))\n",
    "    amp = np.sqrt(sc) * fct\n",
    "    return freq, amp*1000 # in c/d and parts-per-thousand (ppt)\n",
    "\n",
    "freq, amp = calc_lomb_scargle(time, flux)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "\n",
    "def plot_fftlightcurve(freq, amp, title='', sourceid=''):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(freq, amp, 'k-')  # Plotting as a line instead of scatter dots\n",
    "    plt.xlabel('Frequency (c/d)')\n",
    "    plt.ylabel('Amplitude (parts-per-thousand)')\n",
    "\n",
    "    # Exclude the zero-frequency component\n",
    "    non_zero_indices = np.where(freq != 0)\n",
    "    freq = freq[non_zero_indices]\n",
    "    amp = amp[non_zero_indices]\n",
    "\n",
    "    # Mask the data for frequencies > 5\n",
    "    mask = (freq > 5) & (freq < 24)\n",
    "    freq_masked = freq[mask]\n",
    "    amp_masked = amp[mask]\n",
    "\n",
    "    # Mask the data for frequencies between 60 and 80\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    freq_noise = freq[noise_mask]\n",
    "    amp_noise = amp[noise_mask]\n",
    "\n",
    "    # Compute the average amplitude for this range\n",
    "    average_noise_amplitude = np.mean(amp_noise)\n",
    "    print(f\"The average amplitude for noise in the range 60-80 c/d for {title} is: {average_noise_amplitude} parts-per-thousand\")\n",
    "\n",
    "    # Identify the frequency with the highest amplitude for frequencies > 5\n",
    "    max_amp_index = np.argmax(amp_masked)\n",
    "    dominant_frequency = freq_masked[max_amp_index]\n",
    "    highest_amplitude = amp_masked[max_amp_index]  # Getting the amplitude value of the highest peak\n",
    "\n",
    "    print(f\"The frequency with the highest amplitude for {title} after 5 c/d is: {dominant_frequency} c/d\")\n",
    "    print(f\"The highest amplitude for {title} after 5 c/d is: {highest_amplitude} parts-per-thousand\")\n",
    "\n",
    "    # Modify the plot title to include the sourceid\n",
    "    complete_title = f\"{title} (Source ID: {sourceid}) Fourier Lightcurve\"\n",
    "    plt.title(complete_title)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Include the sourceid when saving the image file\n",
    "    image_filename = f\"{title.replace(' ', '_')}_{sourceid}_fourierlightcurve.png\"\n",
    "    plt.savefig(image_filename)\n",
    "\n",
    "    # Display the plot in the notebook\n",
    "    plt.show()\n",
    "\n",
    "    # Download the image\n",
    "    #files.download(image_filename)\n",
    "\n",
    "    # Save the FFT data to a CSV and download\n",
    "    csv_filename = f\"{title.replace(' ', '_')}_{sourceid}_fourierlightcurve.csv\"\n",
    "    data = np.column_stack((freq, amp))\n",
    "    np.savetxt(csv_filename, data, delimiter=',', header='Frequency,Amplitude', comments='')\n",
    "    files.download(csv_filename)\n",
    "\n",
    "plot_fftlightcurve(freq, amp, title=star, sourceid=sourceid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CREATE PAGE OF FIGURES FOR STARS WITH 120S DATA\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct\n",
    "    return freq, amp * 1000\n",
    "\n",
    "def plot_all(time, flux, freq, amp, id, save_path_prefix):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    axs[0, 0].plot(time, flux, 'k-')\n",
    "    axs[0, 0].set_xlabel('Time')\n",
    "    axs[0, 0].set_ylabel('Normalized Flux')\n",
    "    axs[0, 0].set_title(f'{id} Lightcurve')\n",
    "    axs[0, 0].grid(True)\n",
    "\n",
    "    zoom_time_mask = (time >= time[0]) & (time <= time[0] + 27)\n",
    "    axs[0, 1].plot(time[zoom_time_mask], flux[zoom_time_mask], 'k-')\n",
    "    axs[0, 1].set_xlabel('Time')\n",
    "    axs[0, 1].set_ylabel('Normalized Flux')\n",
    "    axs[0, 1].set_title(f'{id} Zoomed Lightcurve (t[0] to t[0]+27)')\n",
    "    axs[0, 1].grid(True)\n",
    "\n",
    "    axs[1, 0].plot(freq, amp, 'k-')\n",
    "    axs[1, 0].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 0].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 0].set_title(f'{id} Amplitude Spectrum')\n",
    "    axs[1, 0].grid(True)\n",
    "\n",
    "    zoom_mask = freq <= 20\n",
    "    axs[1, 1].plot(freq[zoom_mask], amp[zoom_mask], 'k-')\n",
    "    axs[1, 1].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 1].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 1].set_title(f'{id} Zoomed Amplitude Spectrum (0-20 c/d)')\n",
    "    axs[1, 1].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.suptitle(f'Star ID: {id}', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    combined_path = f\"{save_path_prefix}_combined.png\"\n",
    "    plt.savefig(combined_path)\n",
    "    plt.close(fig)\n",
    "    print(f\"{id} combined plots saved as {combined_path}\")\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/120/ClustersOfInterestCut_120s.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/120/output_analysis_results.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "for star_id in df['GaiaDR2']:\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "\n",
    "        search_result = search_lightcurve(star, mission='TESS', author='SPOC', exptime=120)\n",
    "        lc_collection = search_result.download_all()\n",
    "        if lc_collection is not None:\n",
    "            lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "\n",
    "            time = lc.time.value\n",
    "            flux = lc.flux.value\n",
    "            nan_mask = ~np.isnan(time) & ~np.isnan(flux)\n",
    "            time = time[nan_mask]\n",
    "            flux = flux[nan_mask]\n",
    "\n",
    "            freq, amp = calc_lomb_scargle(time, flux)\n",
    "\n",
    "            save_path_prefix = os.path.join(os.path.dirname(input_csv_path), f\"{star_id}\")\n",
    "\n",
    "            plot_all(time, flux, freq, amp, star_id, save_path_prefix)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE PAGE OF PLOTS FOR TESS-SPOC 200S DATA\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct\n",
    "    return freq, amp * 1000\n",
    "\n",
    "def plot_all(time, flux, freq, amp, id, save_path_prefix):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    axs[0, 0].plot(time, flux, 'k-')\n",
    "    axs[0, 0].set_xlabel('Time')\n",
    "    axs[0, 0].set_ylabel('Normalized Flux')\n",
    "    axs[0, 0].set_title(f'{id} Lightcurve')\n",
    "    axs[0, 0].grid(True)\n",
    "\n",
    "    zoom_time_mask = (time >= time[0]) & (time <= time[0] + 27)\n",
    "    axs[0, 1].plot(time[zoom_time_mask], flux[zoom_time_mask], 'k-')\n",
    "    axs[0, 1].set_xlabel('Time')\n",
    "    axs[0, 1].set_ylabel('Normalized Flux')\n",
    "    axs[0, 1].set_title(f'{id} Zoomed Lightcurve (t[0] to t[0]+27)')\n",
    "    axs[0, 1].grid(True)\n",
    "\n",
    "    axs[1, 0].plot(freq, amp, 'k-')\n",
    "    axs[1, 0].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 0].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 0].set_title(f'{id} Amplitude Spectrum')\n",
    "    axs[1, 0].grid(True)\n",
    "\n",
    "    zoom_mask = freq <= 20\n",
    "    axs[1, 1].plot(freq[zoom_mask], amp[zoom_mask], 'k-')\n",
    "    axs[1, 1].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 1].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 1].set_title(f'{id} Zoomed Amplitude Spectrum (0-20 c/d)')\n",
    "    axs[1, 1].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.suptitle(f'Star ID: {id}', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    combined_path = f\"{save_path_prefix}_combined.png\"\n",
    "    plt.savefig(combined_path)\n",
    "    plt.close(fig)\n",
    "    print(f\"{id} combined plots saved as {combined_path}\")\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/120/ClustersOfInterestCut_120s.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/120/output_analysis_results.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "for star_id in df['GaiaDR2']:\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "\n",
    "        search_result = search_lightcurve(star, mission='TESS', author='SPOC', exptime=120)\n",
    "        lc_collection = search_result.download_all()\n",
    "        if lc_collection is not None:\n",
    "            lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "\n",
    "            time = lc.time.value\n",
    "            flux = lc.flux.value\n",
    "            nan_mask = ~np.isnan(time) & ~np.isnan(flux)\n",
    "            time = time[nan_mask]\n",
    "            flux = flux[nan_mask]\n",
    "\n",
    "            freq, amp = calc_lomb_scargle(time, flux)\n",
    "\n",
    "            save_path_prefix = os.path.join(os.path.dirname(input_csv_path), f\"{star_id}\")\n",
    "\n",
    "            plot_all(time, flux, freq, amp, star_id, save_path_prefix)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct\n",
    "    return freq, amp * 1000\n",
    "\n",
    "def plot_all(time, flux, freq, amp, id, save_path_prefix):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.tight_layout()\n",
    "    plt.suptitle(f'Star ID: {id}', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    combined_path = f\"{save_path_prefix}_combined.png\"\n",
    "    plt.savefig(combined_path)\n",
    "    plt.close(fig)\n",
    "    print(f\"{id} combined plots saved as {combined_path}\")\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/untitled folder/ClustersOfInterestCut.csv\"\n",
    "df = pd.read_csv(input_csv_path)\n",
    "output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'output_analysis_results.csv')\n",
    "\n",
    "combinations = [{'mission': 'TESS', 'author': 'TESS-SPOC', 'exptime': 200}]\n",
    "\n",
    "output_df = pd.DataFrame(columns=['StarID', 'Mission', 'Author', 'ExpTime', 'ResultPath'])\n",
    "\n",
    "for star_id in df['GaiaDR2']:\n",
    "    found_data = False\n",
    "    save_path_prefix = os.path.join(os.path.dirname(input_csv_path), f\"{star_id}\")\n",
    "    for combo in combinations:\n",
    "        try:\n",
    "            search_result = search_lightcurve(f'GAIA DR2 {star_id}', mission=combo['mission'], author=combo['author'], exptime=combo['exptime'])\n",
    "            lc_collection = search_result.download_all()\n",
    "            if lc_collection:\n",
    "                lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "                time = lc.time.value\n",
    "                flux = lc.flux.value\n",
    "                freq, amp = calc_lomb_scargle(time, flux)\n",
    "                plot_all(time, flux, freq, amp, star_id, save_path_prefix)\n",
    "                new_row = pd.DataFrame({'StarID': [star_id], 'Mission': [combo['mission']], 'Author': [combo['author']], 'ExpTime': [combo['exptime']], 'ResultPath': [save_path_prefix]})\n",
    "                output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "                found_data = True\n",
    "                break\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    if not found_data:\n",
    "        new_row = pd.DataFrame({'StarID': [star_id], 'Mission': [None], 'Author': [None], 'ExpTime': [None], 'ResultPath': [None]})\n",
    "        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This one for 200s data (didn't work properly but used this one most recently)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_highest_amp_and_noise(freq, amp):\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    average_noise = np.mean(amp[noise_mask]) if any(noise_mask) else 0\n",
    "    idx_max = np.argmax(amp)\n",
    "    highest_amp = amp[idx_max]\n",
    "    highest_freq = freq[idx_max]\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def plot_all(time, flux, freq, amp, id, save_path_prefix):\n",
    "    if len(time) > 0 and len(flux) > 0:\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        axs[0, 0].plot(time, flux, 'k-')\n",
    "        axs[0, 0].set_xlabel('Time')\n",
    "        axs[0, 0].set_ylabel('Normalized Flux')\n",
    "        axs[0, 0].set_title(f'{id} Lightcurve')\n",
    "        axs[0, 0].grid(True)\n",
    "\n",
    "        axs[0, 1].plot(time, flux, 'k-')\n",
    "        axs[0, 1].set_xlim([time[0], time[0] + 27])\n",
    "        axs[0, 1].set_xlabel('Time')\n",
    "        axs[0, 1].set_ylabel('Normalized Flux')\n",
    "        axs[0, 1].set_title(f'{id} Zoomed Lightcurve')\n",
    "        axs[0, 1].grid(True)\n",
    "\n",
    "        axs[1, 0].plot(freq, amp, 'k-')\n",
    "        axs[1, 0].set_xlabel('Frequency (c/d)')\n",
    "        axs[1, 0].set_ylabel('Amplitude (ppt)')\n",
    "        axs[1, 0].set_title(f'{id} Amplitude Spectrum')\n",
    "        axs[1, 0].grid(True)\n",
    "\n",
    "        axs[1, 1].plot(freq, amp, 'k-')\n",
    "        axs[1, 1].set_xlim([0, 20])\n",
    "        axs[1, 1].set_xlabel('Frequency (c/d)')\n",
    "        axs[1, 1].set_ylabel('Amplitude (ppt)')\n",
    "        axs[1, 1].set_title(f'{id} Zoomed Amplitude Spectrum')\n",
    "        axs[1, 1].grid(True)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.suptitle(f'Star ID: {id}', fontsize=16)\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "        combined_path = f\"{save_path_prefix}_combined.png\"\n",
    "        plt.savefig(combined_path)\n",
    "        plt.close(fig)\n",
    "        print(f\"{id} combined plots saved as {combined_path}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"No valid data for plotting {id}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/untitled folder/ClustersOfInterestCut.csv\"\n",
    "    output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'output_analysis_results.csv')\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "\n",
    "    secondary_combo = {'mission': 'TESS', 'author': 'TESS-SPOC', 'exptime': 200}\n",
    "    output_df = pd.DataFrame(columns=['StarID', 'Mission', 'Author', 'ExpTime', 'ResultPath', 'HighestFrequency', 'HighestAmplitude', 'AverageNoise'])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['120s Data'] == 0:\n",
    "            star_id = row['GaiaDR2']\n",
    "            save_path_prefix = os.path.join(os.path.dirname(input_csv_path), str(star_id))\n",
    "            try:\n",
    "                search_result = search_lightcurve(f'GAIA DR2 {star_id}', mission=secondary_combo['mission'], author=secondary_combo['author'], exptime=secondary_combo['exptime'])\n",
    "                lc_collection = search_result.download_all()\n",
    "                if lc_collection:\n",
    "                    lc = lc_collection.stitch(corrector_func=lambda x: x.remove_nans().remove_outliers())\n",
    "                    time = lc.time.value\n",
    "                    flux = lc.flux.value\n",
    "                    freq, amp = calc_lomb_scargle(time, flux)\n",
    "                    highest_freq, highest_amp, average_noise = find_highest_amp_and_noise(freq, amp)\n",
    "\n",
    "                    output_df = pd.concat([output_df, pd.DataFrame({\n",
    "                        'StarID': [star_id],\n",
    "                        'Mission': [secondary_combo['mission']],\n",
    "                        'Author': [secondary_combo['author']],\n",
    "                        'ExpTime': [secondary_combo['exptime']],\n",
    "                        'ResultPath': [save_path_prefix],\n",
    "                        'HighestFrequency': [highest_freq],\n",
    "                        'HighestAmplitude': [highest_amp],\n",
    "                        'AverageNoise': [average_noise]\n",
    "                    })], ignore_index=True)\n",
    "\n",
    "                    if plot_all(time, flux, freq, amp, star_id, save_path_prefix):\n",
    "                        print(f\"{star_id} processed successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "    output_df.to_csv(output_csv_path, index=False)\n",
    "    print(\"Analysis complete. Results saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to add 200s column to original membership list \n",
    "import pandas as pd\n",
    "\n",
    "def update_csv_with_match(input_csv_path, reference_csv_path, output_csv_path):\n",
    "    try:\n",
    "        df_main = pd.read_csv(input_csv_path)\n",
    "        print(\"Main DataFrame loaded successfully with columns:\", df_main.columns)\n",
    "\n",
    "        df_reference = pd.read_csv(reference_csv_path)\n",
    "        print(\"Reference DataFrame loaded successfully with columns:\", df_reference.columns)\n",
    "\n",
    "        star_ids = set(df_reference['StarID'])\n",
    "        print(f\"Star IDs collected, total count: {len(star_ids)}\")\n",
    "\n",
    "        df_main['200s Data'] = df_main['GaiaDR2'].apply(lambda x: 1 if x in star_ids else 0)\n",
    "        print(\"'200s Data' column added successfully.\")\n",
    "\n",
    "        df_main.to_csv(output_csv_path, index=False)\n",
    "        print(f\"DataFrame saved successfully to {output_csv_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Colour -0.15 to 0/ClustersOfInterestCut(-0.15).csv\"\n",
    "reference_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Colour -0.15 to 0/tessspoc200/output_analysis_resultsnew.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/file2.csv\"\n",
    "\n",
    "update_csv_with_match(input_csv_path, reference_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce a file with stars that don't have 120s data or 200s data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def filter_rows(input_csv_path, output_csv_path):\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "\n",
    "    filtered_df = df[(df['120s Data'] == 0) & (df['200s Data'] == 0)]\n",
    "\n",
    "    filtered_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Colour -0.15 to 0/ClustersOfInterestCut(-0.15).csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Colour -0.15 to 0/file3.csv\"\n",
    "\n",
    "filter_rows(input_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightkurve import search_lightcurve\n",
    "\n",
    "def fetch_light_curves(input_csv_path, output_csv_path, rejects_csv_path):\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "\n",
    "    results_list = []\n",
    "    rejects_list = []\n",
    "\n",
    "    for id in df['GaiaDR2']:\n",
    "        star = f'GAIA DR2 {id}'\n",
    "        print(f\"Processing {star}...\")\n",
    "\n",
    "        try:\n",
    "            search_result = search_lightcurve(star)\n",
    "            if search_result.table is not None and len(search_result) > 0:\n",
    "                summary = {\n",
    "                    'StarID': id,\n",
    "                    'Results': str(search_result)\n",
    "                }\n",
    "                results_list.append(summary)\n",
    "                print(f\"Data found for {star}.\")\n",
    "            else:\n",
    "                results_list.append({'StarID': id, 'Results': 'No data found'})\n",
    "                rejects_list.append({'StarID': id})\n",
    "                print(f\"No data found for {star}. Added to rejects.\")\n",
    "        except Exception as e:\n",
    "            results_list.append({'StarID': id, 'Results': f'Error: {e}'})\n",
    "            print(f\"Error encountered for {star}: {e}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    rejects_df = pd.DataFrame(rejects_list)\n",
    "\n",
    "    results_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Results saved to {output_csv_path}\")\n",
    "\n",
    "    rejects_df.to_csv(rejects_csv_path, index=False)\n",
    "    print(f\"Rejects saved to {rejects_csv_path}\")\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/file3.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/file4.csv\"\n",
    "rejects_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/rejects.csv\"\n",
    "\n",
    "fetch_light_curves(input_csv_path, output_csv_path, rejects_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE PLOTS FOR QLP 200S DATA\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_metrics(freq, amp):\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    average_noise = np.mean(amp[noise_mask]) if np.any(noise_mask) else 0\n",
    "\n",
    "    valid_mask = freq > 0\n",
    "    freq_valid = freq[valid_mask]\n",
    "    amp_valid = amp[valid_mask]\n",
    "\n",
    "    idx_max = np.argmax(amp_valid)\n",
    "    highest_amp = amp_valid[idx_max]\n",
    "    highest_freq = freq_valid[idx_max]\n",
    "\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def plot_all(time, flux, freq, amp, id, save_path_prefix):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    axs[0, 0].plot(time, flux, 'k-')\n",
    "    axs[0, 0].set_xlabel('Time')\n",
    "    axs[0, 0].set_ylabel('Normalized Flux')\n",
    "    axs[0, 0].set_title(f'{id} Lightcurve')\n",
    "    axs[0, 0].grid(True)\n",
    "\n",
    "    zoom_time_mask = (time >= time[0]) & (time <= time[0] + 27)\n",
    "    axs[0, 1].plot(time[zoom_time_mask], flux[zoom_time_mask], 'k-')\n",
    "    axs[0, 1].set_xlabel('Time')\n",
    "    axs[0, 1].set_ylabel('Normalized Flux')\n",
    "    axs[0, 1].set_title(f'{id} Zoomed Lightcurve (t[0] to t[0]+27)')\n",
    "    axs[0, 1].grid(True)\n",
    "\n",
    "    axs[1, 0].plot(freq, amp, 'k-')\n",
    "    axs[1, 0].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 0].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 0].set_title(f'{id} Amplitude Spectrum')\n",
    "    axs[1, 0].grid(True)\n",
    "\n",
    "    zoom_mask = freq <= 20\n",
    "    axs[1, 1].plot(freq[zoom_mask], amp[zoom_mask], 'k-')\n",
    "    axs[1, 1].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 1].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 1].set_title(f'{id} Zoomed Amplitude Spectrum (0-20 c/d)')\n",
    "    axs[1, 1].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.suptitle(f'Star ID: {id}', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    combined_path = f\"{save_path_prefix}_combined.png\"\n",
    "    plt.savefig(combined_path)\n",
    "    plt.close(fig)\n",
    "    return combined_path\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/qlp200/file3onestar.csv\"\n",
    "output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'output_analysis_resultsnew.csv')\n",
    "df = pd.read_csv(input_csv_path)\n",
    "output_df = pd.DataFrame(columns=['StarID', 'HighestFrequency', 'HighestAmplitude', 'AverageNoise', 'PlotPath'])\n",
    "\n",
    "for star_id in df['GaiaDR2']:\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "        search_result = search_lightcurve(star, author='QLP', exptime=200)\n",
    "        lc_collection = search_result.download_all()\n",
    "        if lc_collection:\n",
    "            lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "            time = lc.time.value\n",
    "            flux = lc.flux.value\n",
    "            freq, amp = calc_lomb_scargle(time, flux)\n",
    "            highest_freq, highest_amp, average_noise = find_metrics(freq, amp)\n",
    "            save_path_prefix = os.path.join(os.path.dirname(input_csv_path), f\"{star_id}\")\n",
    "            plot_path = plot_all(time, flux, freq, amp, star_id, save_path_prefix)\n",
    "            output_df = pd.concat([output_df, pd.DataFrame([{\n",
    "                'StarID': star_id,\n",
    "                'HighestFrequency': highest_freq,\n",
    "                'HighestAmplitude': highest_amp,\n",
    "                'AverageNoise': average_noise,\n",
    "                'PlotPath': plot_path\n",
    "            }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to add 1800s QLP column to original membership list \n",
    "import pandas as pd\n",
    "\n",
    "def update_csv_with_match(input_csv_path, reference_csv_path, output_csv_path):\n",
    "    try:\n",
    "        df_main = pd.read_csv(input_csv_path)\n",
    "        print(\"Main DataFrame loaded successfully with columns:\", df_main.columns)\n",
    "\n",
    "        df_reference = pd.read_csv(reference_csv_path)\n",
    "        print(\"Reference DataFrame loaded successfully with columns:\", df_reference.columns)\n",
    "\n",
    "        star_ids = set(df_reference['StarID'])\n",
    "        print(f\"Star IDs collected, total count: {len(star_ids)}\")\n",
    "\n",
    "        df_main['1800s QLP Data'] = df_main['GaiaDR2'].apply(lambda x: 1 if x in star_ids else 0)\n",
    "        print(\"'200s QLP Data' column added successfully.\")\n",
    "\n",
    "        df_main.to_csv(output_csv_path, index=False)\n",
    "        print(f\"DataFrame saved successfully to {output_csv_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/ClustersOfInterestCut.csv\"\n",
    "reference_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/qlp1800/output_analysis_results.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/ClustersOfInterestCut.csv\"\n",
    "\n",
    "update_csv_with_match(input_csv_path, reference_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce a file with stars that don't have 120s data or 200s data or 200 QLP data or 600S TESS-SPOC data or 600S QLP data or 1800s TESS-SPOC data or 1800s QLP data\n",
    "import pandas as pd\n",
    "\n",
    "def filter_rows(input_csv_path, output_csv_path):\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "\n",
    "    filtered_df = df[(df['120s Data'] == 0) & \n",
    "                     (df['200s Data'] == 0) & \n",
    "                     (df['200s QLP Data'] == 0) & \n",
    "                     (df['600s TESS-SPOC Data'] == 0) & \n",
    "                     (df['600s QLP Data'] == 0) & \n",
    "                     (df['1800s TESS-SPOC Data'] == 0) & \n",
    "                     (df['1800s QLP Data'] == 0)]\n",
    "\n",
    "    filtered_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/ClustersOfInterestCut.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/file3.csv\"\n",
    "\n",
    "filter_rows(input_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE PLOTS FOR TESS-SPOC 600s DATA\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_metrics(freq, amp):\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    average_noise = np.mean(amp[noise_mask]) if np.any(noise_mask) else 0\n",
    "\n",
    "    valid_mask = freq > 0\n",
    "    freq_valid = freq[valid_mask]\n",
    "    amp_valid = amp[valid_mask]\n",
    "\n",
    "    idx_max = np.argmax(amp_valid)\n",
    "    highest_amp = amp_valid[idx_max]\n",
    "    highest_freq = freq_valid[idx_max]\n",
    "\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def plot_all(time, flux, freq, amp, id, save_path_prefix):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    axs[0, 0].plot(time, flux, 'k-')\n",
    "    axs[0, 0].set_xlabel('Time')\n",
    "    axs[0, 0].set_ylabel('Normalized Flux')\n",
    "    axs[0, 0].set_title(f'{id} Lightcurve')\n",
    "    axs[0, 0].grid(True)\n",
    "\n",
    "    zoom_time_mask = (time >= time[0]) & (time <= time[0] + 27)\n",
    "    axs[0, 1].plot(time[zoom_time_mask], flux[zoom_time_mask], 'k-')\n",
    "    axs[0, 1].set_xlabel('Time')\n",
    "    axs[0, 1].set_ylabel('Normalized Flux')\n",
    "    axs[0, 1].set_title(f'{id} Zoomed Lightcurve (t[0] to t[0]+27)')\n",
    "    axs[0, 1].grid(True)\n",
    "\n",
    "    axs[1, 0].plot(freq, amp, 'k-')\n",
    "    axs[1, 0].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 0].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 0].set_title(f'{id} Amplitude Spectrum')\n",
    "    axs[1, 0].grid(True)\n",
    "\n",
    "    zoom_mask = freq <= 20\n",
    "    axs[1, 1].plot(freq[zoom_mask], amp[zoom_mask], 'k-')\n",
    "    axs[1, 1].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 1].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 1].set_title(f'{id} Zoomed Amplitude Spectrum (0-20 c/d)')\n",
    "    axs[1, 1].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.suptitle(f'Star ID: {id}', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    combined_path = f\"{save_path_prefix}_combined.png\"\n",
    "    plt.savefig(combined_path)\n",
    "    plt.close(fig)\n",
    "    return combined_path\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/tessspoc600/file3.csv\"\n",
    "output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'output_analysis_results.csv')\n",
    "df = pd.read_csv(input_csv_path)\n",
    "output_df = pd.DataFrame(columns=['StarID', 'HighestFrequency', 'HighestAmplitude', 'AverageNoise', 'PlotPath'])\n",
    "\n",
    "for star_id in df['GaiaDR2']:\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "        search_result = search_lightcurve(star, author='TESS-SPOC', exptime=600)\n",
    "        lc_collection = search_result.download_all()\n",
    "        if lc_collection:\n",
    "            lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "            time = lc.time.value\n",
    "            flux = lc.flux.value\n",
    "            freq, amp = calc_lomb_scargle(time, flux)\n",
    "            highest_freq, highest_amp, average_noise = find_metrics(freq, amp)\n",
    "            save_path_prefix = os.path.join(os.path.dirname(input_csv_path), f\"{star_id}\")\n",
    "            plot_path = plot_all(time, flux, freq, amp, star_id, save_path_prefix)\n",
    "            output_df = pd.concat([output_df, pd.DataFrame([{\n",
    "                'StarID': star_id,\n",
    "                'HighestFrequency': highest_freq,\n",
    "                'HighestAmplitude': highest_amp,\n",
    "                'AverageNoise': average_noise,\n",
    "                'PlotPath': plot_path\n",
    "            }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import os\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_metrics(freq, amp):\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    average_noise = np.mean(amp[noise_mask]) if np.any(noise_mask) else 0\n",
    "\n",
    "    mask = freq > 5\n",
    "    freq_above_5 = freq[mask]\n",
    "    amp_above_5 = amp[mask]\n",
    "\n",
    "    if len(amp_above_5) > 0:\n",
    "        idx_max = np.argmax(amp_above_5)\n",
    "        highest_amp = amp_above_5[idx_max]\n",
    "        highest_freq = freq_above_5[idx_max]\n",
    "    else:\n",
    "        highest_amp = None\n",
    "        highest_freq = None\n",
    "\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def process_star_data(star_id):\n",
    "    star = f'GAIA DR2 {star_id}'\n",
    "    search_result = search_lightcurve(star, author='TESS-SPOC', exptime=600)\n",
    "    lc_collection = search_result.download_all()\n",
    "    if lc_collection:\n",
    "        lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "        time = lc.time.value\n",
    "        flux = lc.flux.value\n",
    "        freq, amp = calc_lomb_scargle(time, flux)\n",
    "        return find_metrics(freq, amp)\n",
    "    return None, None, None\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/tessspoc600/output_analysis_results.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/tessspoc600/output_results_analysis22.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_path)\n",
    "output_df = pd.DataFrame(columns=['StarID', 'HighestFrequency', 'HighestAmplitude', 'AverageNoise'])\n",
    "\n",
    "for star_id in df['StarID']:\n",
    "    highest_freq, highest_amp, average_noise = process_star_data(star_id)\n",
    "    if highest_freq is not None:\n",
    "        new_row = pd.DataFrame([{\n",
    "            'StarID': star_id,\n",
    "            'HighestFrequency': highest_freq,\n",
    "            'HighestAmplitude': highest_amp,\n",
    "            'AverageNoise': average_noise\n",
    "        }])\n",
    "        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE PLOTS FOR QLP 600s DATA\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_metrics(freq, amp):\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    average_noise = np.mean(amp[noise_mask]) if np.any(noise_mask) else 0\n",
    "\n",
    "    valid_mask = freq > 0\n",
    "    freq_valid = freq[valid_mask]\n",
    "    amp_valid = amp[valid_mask]\n",
    "\n",
    "    idx_max = np.argmax(amp_valid)\n",
    "    highest_amp = amp_valid[idx_max]\n",
    "    highest_freq = freq_valid[idx_max]\n",
    "\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def plot_all(time, flux, freq, amp, id, save_path_prefix):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    axs[0, 0].plot(time, flux, 'k-')\n",
    "    axs[0, 0].set_xlabel('Time')\n",
    "    axs[0, 0].set_ylabel('Normalized Flux')\n",
    "    axs[0, 0].set_title(f'{id} Lightcurve')\n",
    "    axs[0, 0].grid(True)\n",
    "\n",
    "    zoom_time_mask = (time >= time[0]) & (time <= time[0] + 27)\n",
    "    axs[0, 1].plot(time[zoom_time_mask], flux[zoom_time_mask], 'k-')\n",
    "    axs[0, 1].set_xlabel('Time')\n",
    "    axs[0, 1].set_ylabel('Normalized Flux')\n",
    "    axs[0, 1].set_title(f'{id} Zoomed Lightcurve (t[0] to t[0]+27)')\n",
    "    axs[0, 1].grid(True)\n",
    "\n",
    "    axs[1, 0].plot(freq, amp, 'k-')\n",
    "    axs[1, 0].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 0].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 0].set_title(f'{id} Amplitude Spectrum')\n",
    "    axs[1, 0].grid(True)\n",
    "\n",
    "    zoom_mask = freq <= 20\n",
    "    axs[1, 1].plot(freq[zoom_mask], amp[zoom_mask], 'k-')\n",
    "    axs[1, 1].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 1].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 1].set_title(f'{id} Zoomed Amplitude Spectrum (0-20 c/d)')\n",
    "    axs[1, 1].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.suptitle(f'Star ID: {id}', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    combined_path = f\"{save_path_prefix}_combined.png\"\n",
    "    plt.savefig(combined_path)\n",
    "    plt.close(fig)\n",
    "    return combined_path\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/qlp600/file3.csv\"\n",
    "output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'output_analysis_results.csv')\n",
    "df = pd.read_csv(input_csv_path)\n",
    "output_df = pd.DataFrame(columns=['StarID', 'HighestFrequency', 'HighestAmplitude', 'AverageNoise', 'PlotPath'])\n",
    "\n",
    "for star_id in df['GaiaDR2']:\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "        search_result = search_lightcurve(star, author='QLP', exptime=600)\n",
    "        lc_collection = search_result.download_all()\n",
    "        if lc_collection:\n",
    "            lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "            time = lc.time.value\n",
    "            flux = lc.flux.value\n",
    "            freq, amp = calc_lomb_scargle(time, flux)\n",
    "            highest_freq, highest_amp, average_noise = find_metrics(freq, amp)\n",
    "            save_path_prefix = os.path.join(os.path.dirname(input_csv_path), f\"{star_id}\")\n",
    "            plot_path = plot_all(time, flux, freq, amp, star_id, save_path_prefix)\n",
    "            output_df = pd.concat([output_df, pd.DataFrame([{\n",
    "                'StarID': star_id,\n",
    "                'HighestFrequency': highest_freq,\n",
    "                'HighestAmplitude': highest_amp,\n",
    "                'AverageNoise': average_noise,\n",
    "                'PlotPath': plot_path\n",
    "            }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE PLOTS FOR TESS-SPOC 1800s DATA\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_metrics(freq, amp):\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    average_noise = np.mean(amp[noise_mask]) if np.any(noise_mask) else 0\n",
    "\n",
    "    valid_mask = freq > 0\n",
    "    freq_valid = freq[valid_mask]\n",
    "    amp_valid = amp[valid_mask]\n",
    "\n",
    "    idx_max = np.argmax(amp_valid)\n",
    "    highest_amp = amp_valid[idx_max]\n",
    "    highest_freq = freq_valid[idx_max]\n",
    "\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def plot_all(time, flux, freq, amp, id, save_path_prefix):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    axs[0, 0].plot(time, flux, 'k-')\n",
    "    axs[0, 0].set_xlabel('Time')\n",
    "    axs[0, 0].set_ylabel('Normalized Flux')\n",
    "    axs[0, 0].set_title(f'{id} Lightcurve')\n",
    "    axs[0, 0].grid(True)\n",
    "\n",
    "    zoom_time_mask = (time >= time[0]) & (time <= time[0] + 27)\n",
    "    axs[0, 1].plot(time[zoom_time_mask], flux[zoom_time_mask], 'k-')\n",
    "    axs[0, 1].set_xlabel('Time')\n",
    "    axs[0, 1].set_ylabel('Normalized Flux')\n",
    "    axs[0, 1].set_title(f'{id} Zoomed Lightcurve (t[0] to t[0]+27)')\n",
    "    axs[0, 1].grid(True)\n",
    "\n",
    "    axs[1, 0].plot(freq, amp, 'k-')\n",
    "    axs[1, 0].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 0].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 0].set_title(f'{id} Amplitude Spectrum')\n",
    "    axs[1, 0].grid(True)\n",
    "\n",
    "    zoom_mask = freq <= 20\n",
    "    axs[1, 1].plot(freq[zoom_mask], amp[zoom_mask], 'k-')\n",
    "    axs[1, 1].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 1].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 1].set_title(f'{id} Zoomed Amplitude Spectrum (0-20 c/d)')\n",
    "    axs[1, 1].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.suptitle(f'Star ID: {id}', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    combined_path = f\"{save_path_prefix}_combined.png\"\n",
    "    plt.savefig(combined_path)\n",
    "    plt.close(fig)\n",
    "    return combined_path\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/tessspoc1800/file3.csv\"\n",
    "output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'output_analysis_results.csv')\n",
    "df = pd.read_csv(input_csv_path)\n",
    "output_df = pd.DataFrame(columns=['StarID', 'HighestFrequency', 'HighestAmplitude', 'AverageNoise', 'PlotPath'])\n",
    "\n",
    "for star_id in df['GaiaDR2']:\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "        search_result = search_lightcurve(star, author='TESS-SPOC', exptime=1800)\n",
    "        lc_collection = search_result.download_all()\n",
    "        if lc_collection:\n",
    "            lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "            time = lc.time.value\n",
    "            flux = lc.flux.value\n",
    "            freq, amp = calc_lomb_scargle(time, flux)\n",
    "            highest_freq, highest_amp, average_noise = find_metrics(freq, amp)\n",
    "            save_path_prefix = os.path.join(os.path.dirname(input_csv_path), f\"{star_id}\")\n",
    "            plot_path = plot_all(time, flux, freq, amp, star_id, save_path_prefix)\n",
    "            output_df = pd.concat([output_df, pd.DataFrame([{\n",
    "                'StarID': star_id,\n",
    "                'HighestFrequency': highest_freq,\n",
    "                'HighestAmplitude': highest_amp,\n",
    "                'AverageNoise': average_noise,\n",
    "                'PlotPath': plot_path\n",
    "            }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE PLOTS FOR QLP 1800s DATA\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_metrics(freq, amp):\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    average_noise = np.mean(amp[noise_mask]) if np.any(noise_mask) else 0\n",
    "\n",
    "    valid_mask = freq > 0\n",
    "    freq_valid = freq[valid_mask]\n",
    "    amp_valid = amp[valid_mask]\n",
    "\n",
    "    idx_max = np.argmax(amp_valid)\n",
    "    highest_amp = amp_valid[idx_max]\n",
    "    highest_freq = freq_valid[idx_max]\n",
    "\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def plot_all(time, flux, freq, amp, id, save_path_prefix):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    axs[0, 0].plot(time, flux, 'k-')\n",
    "    axs[0, 0].set_xlabel('Time')\n",
    "    axs[0, 0].set_ylabel('Normalized Flux')\n",
    "    axs[0, 0].set_title(f'{id} Lightcurve')\n",
    "    axs[0, 0].grid(True)\n",
    "\n",
    "    zoom_time_mask = (time >= time[0]) & (time <= time[0] + 27)\n",
    "    axs[0, 1].plot(time[zoom_time_mask], flux[zoom_time_mask], 'k-')\n",
    "    axs[0, 1].set_xlabel('Time')\n",
    "    axs[0, 1].set_ylabel('Normalized Flux')\n",
    "    axs[0, 1].set_title(f'{id} Zoomed Lightcurve (t[0] to t[0]+27)')\n",
    "    axs[0, 1].grid(True)\n",
    "\n",
    "    axs[1, 0].plot(freq, amp, 'k-')\n",
    "    axs[1, 0].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 0].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 0].set_title(f'{id} Amplitude Spectrum')\n",
    "    axs[1, 0].grid(True)\n",
    "\n",
    "    zoom_mask = freq <= 20\n",
    "    axs[1, 1].plot(freq[zoom_mask], amp[zoom_mask], 'k-')\n",
    "    axs[1, 1].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 1].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 1].set_title(f'{id} Zoomed Amplitude Spectrum (0-20 c/d)')\n",
    "    axs[1, 1].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.suptitle(f'Star ID: {id}', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    combined_path = f\"{save_path_prefix}_combined.png\"\n",
    "    plt.savefig(combined_path)\n",
    "    plt.close(fig)\n",
    "    return combined_path\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/qlp1800/file3.csv\"\n",
    "output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'output_analysis_results.csv')\n",
    "df = pd.read_csv(input_csv_path)\n",
    "output_df = pd.DataFrame(columns=['StarID', 'HighestFrequency', 'HighestAmplitude', 'AverageNoise', 'PlotPath'])\n",
    "\n",
    "for star_id in df['GaiaDR2']:\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "        search_result = search_lightcurve(star, author='QLP', exptime=1800)\n",
    "        lc_collection = search_result.download_all()\n",
    "        if lc_collection:\n",
    "            lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "            time = lc.time.value\n",
    "            flux = lc.flux.value\n",
    "            freq, amp = calc_lomb_scargle(time, flux)\n",
    "            highest_freq, highest_amp, average_noise = find_metrics(freq, amp)\n",
    "            save_path_prefix = os.path.join(os.path.dirname(input_csv_path), f\"{star_id}\")\n",
    "            plot_path = plot_all(time, flux, freq, amp, star_id, save_path_prefix)\n",
    "            output_df = pd.concat([output_df, pd.DataFrame([{\n",
    "                'StarID': star_id,\n",
    "                'HighestFrequency': highest_freq,\n",
    "                'HighestAmplitude': highest_amp,\n",
    "                'AverageNoise': average_noise,\n",
    "                'PlotPath': plot_path\n",
    "            }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv1 = pd.read_csv(\"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/rejects.csv\")\n",
    "csv2 = pd.read_csv(\"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/file3.csv\")\n",
    "\n",
    "star_ids = set(csv1['StarID'])\n",
    "gaia_ids = set(csv2['GaiaDR2'])\n",
    "\n",
    "only_in_csv1 = star_ids - gaia_ids\n",
    "only_in_csv2 = gaia_ids - star_ids\n",
    "\n",
    "print(\"Entries only in CSV 1 (StarID):\", only_in_csv1)\n",
    "print(\"Entries only in CSV 2 (GaiaDR2):\", only_in_csv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to set up plots to send Tim to confirm\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "csv_directory = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/To Confirm\"\n",
    "output_base_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/To Confirm\"\n",
    "\n",
    "csv_files = ['Close_eclipsingbinary.csv', 'delta_scuti.csv', 'gdor_rotating.csv', 'multiple.csv', 'wildly_oscillating.csv']\n",
    "\n",
    "def find_file(filename, search_path):\n",
    "    for root, dirs, files in os.walk(search_path):\n",
    "        if filename in files:\n",
    "            return os.path.join(root, filename)\n",
    "    return None\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    csv_path = os.path.join(csv_directory, csv_file)\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"File does not exist: {csv_path}\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    folder_name = os.path.splitext(csv_file)[0]\n",
    "    output_path = os.path.join(output_base_path, folder_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    for gaia_id in df['GAIA DR2']:\n",
    "        image_filename = f\"{gaia_id}_combined.png\"\n",
    "        file_path = find_file(image_filename, Path.home())\n",
    "        \n",
    "        if file_path:\n",
    "            shutil.copy(file_path, output_path)\n",
    "        else:\n",
    "            print(f\"File not found: {image_filename}\")\n",
    "\n",
    "print(\"All specified files processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "output_base_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/To Confirm\"\n",
    "\n",
    "csv_folders = [f.path for f in os.scandir(output_base_path) if f.is_dir()]\n",
    "\n",
    "for folder in csv_folders:\n",
    "    csv_file = os.path.join(folder, os.path.basename(folder) + '.csv')\n",
    "    if os.path.exists(csv_file):\n",
    "        df = pd.read_csv(csv_file, dtype={'GAIA DR2': str})\n",
    "        \n",
    "        new_ids = range(1, len(df) + 1)\n",
    "        df['New GAIA DR2'] = new_ids\n",
    "        \n",
    "        df.to_csv(csv_file, index=False)\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            old_filename = f\"{row['GAIA DR2']}_combined.png\"\n",
    "            new_filename = f\"{row['New GAIA DR2']}.png\"\n",
    "            old_file_path = Path(folder) / old_filename\n",
    "            new_file_path = Path(folder) / new_filename\n",
    "            \n",
    "            if old_file_path.exists():\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "            else:\n",
    "                print(f\"File not found: {old_filename}\")\n",
    "\n",
    "print(\"All specified files and CSVs have been updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut membership list between -0.15 and 0 Bp-Rp\n",
    "import pandas as pd\n",
    "\n",
    "def filter_and_save_csv(input_file_path, output_file_path):\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    df['Bp-Rp'] = pd.to_numeric(df['Bp-Rp'], errors='coerce')\n",
    "    df['AbsMag'] = pd.to_numeric(df['AbsMag'], errors='coerce')\n",
    "    \n",
    "    filtered_df = df[(df['Bp-Rp'] >= -0.15) & (df['Bp-Rp'] < 0)]\n",
    "    \n",
    "    filtered_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"Filtered data saved to {output_file_path}\")\n",
    "\n",
    "input_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/ClustersOfInterestCombined.csv\"\n",
    "output_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/ClustersOfInterestCut(-0.15).csv\"\n",
    "\n",
    "filter_and_save_csv(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count how many stars have 120s data for new stars (-0.15) \n",
    "import pandas as pd\n",
    "\n",
    "def sum_and_count_stars(file_path, data_column, cluster_column):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    df[data_column] = pd.to_numeric(df[data_column], errors='coerce')\n",
    "    \n",
    "    total_sum = df[data_column].sum()\n",
    "    print(f\"The total sum of the '{data_column}' column is: {total_sum}\")\n",
    "    \n",
    "    cluster_counts = df[cluster_column].value_counts()\n",
    "    \n",
    "    print(\"\\nNumber of stars in each cluster:\")\n",
    "    for cluster, count in cluster_counts.items():\n",
    "        print(f\"{cluster}: {count}\")\n",
    "\n",
    "file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Colour -0.15 to 0/ClustersOfInterestCut(-0.15).csv\"\n",
    "\n",
    "sum_and_count_stars(file_path, '120s Data', 'Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE PAGE OF FIGURES FOR STARS WITH 200s DATA - new stars\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_metrics(freq, amp):\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    average_noise = np.mean(amp[noise_mask]) if np.any(noise_mask) else 0\n",
    "\n",
    "    valid_mask = freq > 0\n",
    "    freq_valid = freq[valid_mask]\n",
    "    amp_valid = amp[valid_mask]\n",
    "\n",
    "    idx_max = np.argmax(amp_valid)\n",
    "    highest_amp = amp_valid[idx_max]\n",
    "    highest_freq = freq_valid[idx_max]\n",
    "\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def plot_all(time, flux, freq, amp, id, save_path_prefix):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    axs[0, 0].plot(time, flux, 'k-')\n",
    "    axs[0, 0].set_xlabel('Time')\n",
    "    axs[0, 0].set_ylabel('Normalized Flux')\n",
    "    axs[0, 0].set_title(f'{id} Lightcurve')\n",
    "    axs[0, 0].grid(True)\n",
    "\n",
    "    zoom_time_mask = (time >= time[0]) & (time <= time[0] + 27)\n",
    "    axs[0, 1].plot(time[zoom_time_mask], flux[zoom_time_mask], 'k-')\n",
    "    axs[0, 1].set_xlabel('Time')\n",
    "    axs[0, 1].set_ylabel('Normalized Flux')\n",
    "    axs[0, 1].set_title(f'{id} Zoomed Lightcurve (t[0] to t[0]+27)')\n",
    "    axs[0, 1].grid(True)\n",
    "\n",
    "    axs[1, 0].plot(freq, amp, 'k-')\n",
    "    axs[1, 0].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 0].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 0].set_title(f'{id} Amplitude Spectrum')\n",
    "    axs[1, 0].grid(True)\n",
    "\n",
    "    zoom_mask = freq <= 20\n",
    "    axs[1, 1].plot(freq[zoom_mask], amp[zoom_mask], 'k-')\n",
    "    axs[1, 1].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 1].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 1].set_title(f'{id} Zoomed Amplitude Spectrum (0-20 c/d)')\n",
    "    axs[1, 1].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.suptitle(f'Star ID: {id}', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    combined_path = f\"{save_path_prefix}_combined.png\"\n",
    "    plt.savefig(combined_path)\n",
    "    plt.close(fig)\n",
    "    return combined_path\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Colour -0.15 to 0/k260/file3.csv\"\n",
    "output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'output_analysis_resultsnew.csv')\n",
    "df = pd.read_csv(input_csv_path)\n",
    "output_df = pd.DataFrame(columns=['StarID', 'HighestFrequency', 'HighestAmplitude', 'AverageNoise', 'PlotPath'])\n",
    "\n",
    "for star_id in df['GaiaDR2']:\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "        search_result = search_lightcurve(star, author='K2', exptime=60)\n",
    "        lc_collection = search_result.download_all()\n",
    "        if lc_collection:\n",
    "            lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "            time = lc.time.value\n",
    "            flux = lc.flux.value\n",
    "            freq, amp = calc_lomb_scargle(time, flux)\n",
    "            highest_freq, highest_amp, average_noise = find_metrics(freq, amp)\n",
    "            save_path_prefix = os.path.join(os.path.dirname(input_csv_path), f\"{star_id}\")\n",
    "            plot_path = plot_all(time, flux, freq, amp, star_id, save_path_prefix)\n",
    "            output_df = pd.concat([output_df, pd.DataFrame([{\n",
    "                'StarID': star_id,\n",
    "                'HighestFrequency': highest_freq,\n",
    "                'HighestAmplitude': highest_amp,\n",
    "                'AverageNoise': average_noise,\n",
    "                'PlotPath': plot_path\n",
    "            }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce a file with stars that don't have 120s data or 200s data or 200 QLP data or 600S TESS-SPOC data or 600S QLP data or 1800s TESS-SPOC data or 1800s QLP data\n",
    "import pandas as pd\n",
    "\n",
    "def filter_rows(input_csv_path, output_csv_path):\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "\n",
    "    filtered_df = df[(df['120s Data'] == 0) & \n",
    "                     (df['200s Data'] == 0) & \n",
    "                     (df['200s QLP Data'] == 0) & \n",
    "                     (df['600s TESS-SPOC Data'] == 0) & \n",
    "                     (df['600s QLP Data'] == 0) & \n",
    "                     (df['1800s TESS-SPOC Data'] == 0)]\n",
    "\n",
    "    filtered_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Colour -0.15 to 0/file2.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Colour -0.15 to 0/file3.csv\"\n",
    "\n",
    "filter_rows(input_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to add 200s column to original membership list \n",
    "import pandas as pd\n",
    "\n",
    "def update_csv_with_match(input_csv_path, reference_csv_path, output_csv_path):\n",
    "    try:\n",
    "        df_main = pd.read_csv(input_csv_path)\n",
    "        print(\"Main DataFrame loaded successfully with columns:\", df_main.columns)\n",
    "\n",
    "        df_reference = pd.read_csv(reference_csv_path)\n",
    "        print(\"Reference DataFrame loaded successfully with columns:\", df_reference.columns)\n",
    "\n",
    "        star_ids = set(df_reference['StarID'])\n",
    "        print(f\"Star IDs collected, total count: {len(star_ids)}\")\n",
    "\n",
    "        df_main['60s K2 Data'] = df_main['GaiaDR2'].apply(lambda x: 1 if x in star_ids else 0)\n",
    "        print(\"'60s K2 Data' column added successfully.\")\n",
    "\n",
    "        df_main.to_csv(output_csv_path, index=False)\n",
    "        print(f\"DataFrame saved successfully to {output_csv_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Colour -0.15 to 0/file2.csv\"\n",
    "reference_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Colour -0.15 to 0/k260/output_analysis_resultsnew.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/Colour -0.15 to 0/file2.csv\"\n",
    "\n",
    "update_csv_with_match(input_csv_path, reference_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE TO ADD TIC ID COLUMN FOR NGC2451B\n",
    "from astroquery.mast import Catalogs\n",
    "import pandas as pd\n",
    "\n",
    "cluster_names = [\"NGC2451B\"]\n",
    "base_directory = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/\"\n",
    "\n",
    "for cluster_name in cluster_names:\n",
    "    file_name = f\"{cluster_name} - Cantat-Gaudin.csv\"\n",
    "    file_path = f\"{base_directory}{file_name}\"\n",
    "    print(f\"\\nLoading the file: {file_path}\")\n",
    "    df = pd.read_csv(file_path, delimiter=r'\\s+', header=None)\n",
    "\n",
    "    print(\"Extracting GAIA IDs...\")\n",
    "    gaia_ids = df.iloc[:, 2].values\n",
    "\n",
    "    print(\"Querying TIC IDs for the GAIA IDs...\")\n",
    "    result = Catalogs.query_criteria(catalog=\"Tic\", GAIA=gaia_ids).to_pandas()\n",
    "\n",
    "    df[2] = df[2].astype(str)\n",
    "    result['GAIA'] = result['GAIA'].astype(str)\n",
    "\n",
    "    print(\"Selecting the first TIC ID for each GAIA ID in case of duplicates...\")\n",
    "    result = result.groupby('GAIA').first().reset_index()\n",
    "\n",
    "    print(\"Merging TIC IDs with the original DataFrame...\")\n",
    "    df = df.merge(result[['ID', 'GAIA']], how='left', left_on=2, right_on='GAIA')\n",
    "\n",
    "    df.rename(columns={'ID': 'TIC ID'}, inplace=True)\n",
    "\n",
    "    print(\"TIC IDs added next to corresponding GAIA IDs.\")\n",
    "\n",
    "    output_file = f\"{base_directory}{cluster_name}_with_TIC.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"File saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2: Add sector column for each TIC ID for NGC2451B\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "clusters = ['NGC2451B - Cantat-Gaudin']\n",
    "base_directory = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/'\n",
    "directory_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/120s Data/\"\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_file_path = os.path.join(base_directory, f'{cluster}.csv')\n",
    "    print(f\"Loading the TIC ID file for {cluster}...\")\n",
    "    tic_df = pd.read_csv(cluster_file_path)\n",
    "\n",
    "    if 'TIC' not in tic_df.columns:\n",
    "        raise ValueError(f\"The file for {cluster} does not have a 'TIC' column.\")\n",
    "\n",
    "    tic_df['Sector'] = None\n",
    "\n",
    "    for index, row in tic_df.iterrows():\n",
    "        tic_id = row['TIC']\n",
    "        print(f\"Processing TIC ID: {tic_id} in {cluster}\")\n",
    "\n",
    "        for i in range(1, 79):\n",
    "            file_name = f'all_targets_S{i:03d}_v1.csv'\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            print(f\"Checking against file: {file_name}\")\n",
    "            target_df = pd.read_csv(file_path, skiprows=5)\n",
    "\n",
    "            if target_df.shape[1] > 0:\n",
    "                if tic_id in target_df.iloc[:, 0].values:\n",
    "                    tic_df.at[index, 'Sector'] = i\n",
    "                    print(f\"Match found in file: {file_name}\")\n",
    "                    break\n",
    "\n",
    "    updated_file_path = os.path.join(base_directory, f'updated ({cluster}).csv')\n",
    "    print(f\"Saving the updated file for {cluster}...\")\n",
    "    tic_df.to_csv(updated_file_path, index=False)\n",
    "    print(f\"Processing complete for {cluster}. The updated file has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3: If Sector entry exists, add a 1 in the 120s column for NGC2451B\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "files = ['NGC2451B - Cantat-Gaudin.csv']\n",
    "base_directory = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/'  # Change this to the directory where your files are located\n",
    "\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(base_directory, file_name)\n",
    "    print(f\"Processing {file_name}...\")\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    if 'Sector' not in df.columns:\n",
    "        print(f\"No 'Sector' column found in {file_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    df['120s Data'] = df['Sector'].apply(lambda x: 0 if pd.isnull(x) or x == '' else 1)\n",
    "\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Updated {file_name} has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 4: Convert Gmag to Abs Mag for NGC2451B\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/NGC2451B - Cantat-Gaudin.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['AbsMag'] = df['Gmag'] - 5*np.log10(367.782) + 5\n",
    "\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE PAGE OF FIGURES FOR STARS WITH 120s DATA - NGC2451B\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calc_lomb_scargle(t, y):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    fmax = 100\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_metrics(freq, amp):\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    average_noise = np.mean(amp[noise_mask]) if np.any(noise_mask) else 0\n",
    "\n",
    "    valid_mask = freq > 0\n",
    "    freq_valid = freq[valid_mask]\n",
    "    amp_valid = amp[valid_mask]\n",
    "\n",
    "    idx_max = np.argmax(amp_valid)\n",
    "    highest_amp = amp_valid[idx_max]\n",
    "    highest_freq = freq_valid[idx_max]\n",
    "\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def plot_all(time, flux, freq, amp, id, save_path_prefix):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    axs[0, 0].plot(time, flux, 'k-')\n",
    "    axs[0, 0].set_xlabel('Time')\n",
    "    axs[0, 0].set_ylabel('Normalized Flux')\n",
    "    axs[0, 0].set_title(f'{id} Lightcurve')\n",
    "    axs[0, 0].grid(True)\n",
    "\n",
    "    zoom_time_mask = (time >= time[0]) & (time <= time[0] + 27)\n",
    "    axs[0, 1].plot(time[zoom_time_mask], flux[zoom_time_mask], 'k-')\n",
    "    axs[0, 1].set_xlabel('Time')\n",
    "    axs[0, 1].set_ylabel('Normalized Flux')\n",
    "    axs[0, 1].set_title(f'{id} Zoomed Lightcurve (t[0] to t[0]+27)')\n",
    "    axs[0, 1].grid(True)\n",
    "\n",
    "    axs[1, 0].plot(freq, amp, 'k-')\n",
    "    axs[1, 0].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 0].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 0].set_title(f'{id} Amplitude Spectrum')\n",
    "    axs[1, 0].grid(True)\n",
    "\n",
    "    zoom_mask = freq <= 20\n",
    "    axs[1, 1].plot(freq[zoom_mask], amp[zoom_mask], 'k-')\n",
    "    axs[1, 1].set_xlabel('Frequency (c/d)')\n",
    "    axs[1, 1].set_ylabel('Amplitude (parts-per-thousand)')\n",
    "    axs[1, 1].set_title(f'{id} Zoomed Amplitude Spectrum (0-20 c/d)')\n",
    "    axs[1, 1].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.suptitle(f'Star ID: {id}', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    combined_path = f\"{save_path_prefix}_combined.png\"\n",
    "    plt.savefig(combined_path)\n",
    "    plt.close(fig)\n",
    "    return combined_path\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/NGC2451B/file2.csv\"\n",
    "output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'output_analysis_resultsnew.csv')\n",
    "df = pd.read_csv(input_csv_path)\n",
    "output_df = pd.DataFrame(columns=['StarID', 'HighestFrequency', 'HighestAmplitude', 'AverageNoise', 'PlotPath'])\n",
    "\n",
    "for star_id in df['GaiaDR2']:\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "        search_result = search_lightcurve(star, mission='TESS', exptime=120)\n",
    "        lc_collection = search_result.download_all()\n",
    "        if not lc_collection:\n",
    "            raise ValueError(f\"No data found for target 'GAIA DR2 {star_id}'\")\n",
    "    except ValueError as e:\n",
    "        if 'No data found for target' in str(e):\n",
    "            try:\n",
    "                star = f'GAIA DR3 {star_id}'\n",
    "                search_result = search_lightcurve(star, mission='TESS', exptime=120)\n",
    "                lc_collection = search_result.download_all()\n",
    "                if not lc_collection:\n",
    "                    raise ValueError(f\"No data found for target 'GAIA DR3 {star_id}'\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process data for {star_id} using GAIA DR3: {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Failed to process data for {star_id} using GAIA DR2: {e}\")\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "        time = lc.time.value\n",
    "        flux = lc.flux.value\n",
    "        freq, amp = calc_lomb_scargle(time, flux)\n",
    "        highest_freq, highest_amp, average_noise = find_metrics(freq, amp)\n",
    "        save_path_prefix = os.path.join(os.path.dirname(input_csv_path), f\"{star_id}\")\n",
    "        plot_path = plot_all(time, flux, freq, amp, star_id, save_path_prefix)\n",
    "        output_df = pd.concat([output_df, pd.DataFrame([{\n",
    "            'StarID': star_id,\n",
    "            'HighestFrequency': highest_freq,\n",
    "            'HighestAmplitude': highest_amp,\n",
    "            'AverageNoise': average_noise,\n",
    "            'PlotPath': plot_path\n",
    "        }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to add 120s column to original membership list - NGC2451B\n",
    "import pandas as pd\n",
    "\n",
    "def update_csv_with_match(input_csv_path, reference_csv_path, output_csv_path):\n",
    "    try:\n",
    "        df_main = pd.read_csv(input_csv_path)\n",
    "        print(\"Main DataFrame loaded successfully with columns:\", df_main.columns)\n",
    "\n",
    "        df_reference = pd.read_csv(reference_csv_path)\n",
    "        print(\"Reference DataFrame loaded successfully with columns:\", df_reference.columns)\n",
    "\n",
    "        star_ids = set(df_reference['StarID'])\n",
    "        print(f\"Star IDs collected, total count: {len(star_ids)}\")\n",
    "\n",
    "        df_main['120s Data'] = df_main['GaiaDR2'].apply(lambda x: 1 if x in star_ids else 0)\n",
    "        print(\"'120s Data' column added successfully.\")\n",
    "\n",
    "        df_main.to_csv(output_csv_path, index=False)\n",
    "        print(f\"DataFrame saved successfully to {output_csv_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/NGC2451B/file2.csv\"\n",
    "reference_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/NGC2451B/120s/output_analysis_resultsnew.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/NGC2451B/file2.csv\"\n",
    "\n",
    "update_csv_with_match(input_csv_path, reference_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce a file with stars that don't have 120s data or 200s data or 200 QLP data or 600S TESS-SPOC data or 600S QLP data or 1800s TESS-SPOC data or 1800s QLP data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def filter_rows(input_csv_path, output_csv_path):\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "\n",
    "    filtered_df = df[(df['120s Data'] == 0) & (df['200s TESS-SPOC Data'] == 0)]\n",
    "\n",
    "    filtered_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/NGC2451B/file2.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/NGC2451B/file3.csv\"\n",
    "\n",
    "filter_rows(input_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process skewness for delta scuti and potentially delta scuti\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.stats import skew\n",
    "\n",
    "def calc_lomb_scargle(t, y, fmax):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_metrics(freq, amp):\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    average_noise = np.mean(amp[noise_mask]) if np.any(noise_mask) else 0\n",
    "\n",
    "    valid_mask = freq > 0\n",
    "    freq_valid = freq[valid_mask]\n",
    "    amp_valid = amp[valid_mask]\n",
    "\n",
    "    idx_max = np.argmax(amp_valid)\n",
    "    highest_amp = amp_valid[idx_max]\n",
    "    highest_freq = freq_valid[idx_max]\n",
    "\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def calculate_skewness(amp):\n",
    "    amp = amp[np.isfinite(amp)]\n",
    "    if len(amp) > 0:\n",
    "        return skew(amp)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_nyquist_frequency(exposure_time):\n",
    "    return 1 / (2 * exposure_time / 86400)\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/process_skewness_for.csv\"\n",
    "output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'skewness.csv')\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "df['HighestFrequency'] = np.nan\n",
    "df['HighestAmplitude'] = np.nan\n",
    "df['AverageNoise'] = np.nan\n",
    "df['Skewness'] = np.nan\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    star_id = row['GaiaDR2']\n",
    "    exposure_time = row['Exposure Time']\n",
    "    author = row['Author']\n",
    "    nyquist_frequency = calculate_nyquist_frequency(exposure_time)\n",
    "\n",
    "    print(f\"Processing star ID {star_id} with author {author}...\")\n",
    "\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "        if author == 'SPOC':\n",
    "            search_result = search_lightcurve(star, mission='TESS', author='SPOC', exptime=exposure_time)\n",
    "        elif author == 'TESS-SPOC':\n",
    "            search_result = search_lightcurve(star, mission='TESS', author='TESS-SPOC', exptime=exposure_time)\n",
    "        elif author == 'QLP':\n",
    "            search_result = search_lightcurve(star, author='QLP', exptime=exposure_time)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown author '{author}' for star ID {star_id}\")\n",
    "        \n",
    "        lc_collection = search_result.download_all()\n",
    "        if not lc_collection:\n",
    "            raise ValueError(f\"No data found for target 'GAIA DR2 {star_id}'\")\n",
    "    except ValueError as e:\n",
    "        if 'No data found for target' in str(e):\n",
    "            try:\n",
    "                star = f'GAIA DR3 {star_id}'\n",
    "                if author == 'SPOC':\n",
    "                    search_result = search_lightcurve(star, mission='TESS', author='SPOC', exptime=exposure_time)\n",
    "                elif author == 'TESS-SPOC':\n",
    "                    search_result = search_lightcurve(star, mission='TESS', author='TESS-SPOC', exptime=exposure_time)\n",
    "                elif author == 'QLP':\n",
    "                    search_result = search_lightcurve(star, author='QLP', exptime=exposure_time)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown author '{author}' for star ID {star_id}\")\n",
    "                \n",
    "                lc_collection = search_result.download_all()\n",
    "                if not lc_collection:\n",
    "                    raise ValueError(f\"No data found for target 'GAIA DR3 {star_id}'\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process data for {star_id} using GAIA DR3: {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Failed to process data for {star_id} using GAIA DR2: {e}\")\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "        time = lc.time.value\n",
    "        flux = lc.flux.value\n",
    "        freq, amp = calc_lomb_scargle(time, flux, nyquist_frequency)\n",
    "        highest_freq, highest_amp, average_noise = find_metrics(freq, amp)\n",
    "        skewness = calculate_skewness(amp)\n",
    "        \n",
    "        df.at[idx, 'HighestFrequency'] = highest_freq\n",
    "        df.at[idx, 'HighestAmplitude'] = highest_amp\n",
    "        df.at[idx, 'AverageNoise'] = average_noise\n",
    "        df.at[idx, 'Skewness'] = skewness\n",
    "\n",
    "        print(f\"Completed processing for star ID {star_id}. Skewness: {skewness}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce skewness histograms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/skewness.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a new column 'log10(Skewness)' for valid positive skewness values\n",
    "df['log10(Skewness)'] = np.where(df['Skewness'] > 0, np.log10(df['Skewness']), np.nan)\n",
    "\n",
    "# Filter the DataFrame based on 'Delta Scuti' values\n",
    "df_delta_scuti_1 = df[df['Delta Scuti'] == 1]\n",
    "df_delta_scuti_2 = df[df['Delta Scuti'] == 2]\n",
    "\n",
    "# Plot histogram for 'Delta Scuti' == 1\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(df_delta_scuti_1['log10(Skewness)'].dropna(), bins=20, alpha=0.7, label='Delta Scuti = 1')\n",
    "plt.xlabel('log10(Skewness)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of log10(Skewness) for Delta Scuti = 1')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot histogram for 'Delta Scuti' == 2\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(df_delta_scuti_2['log10(Skewness)'].dropna(), bins=20, alpha=0.7, label='Delta Scuti = 2')\n",
    "plt.xlabel('log10(Skewness)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of log10(Skewness) for Delta Scuti = 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a new column identifying which have log10(Skewness) > 0.5\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/skewness.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['log10(Skewness)>0.5'] = (df['log10(Skewness)'] > 0.5).astype(int)\n",
    "\n",
    "output_csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/skewness1.csv\"\n",
    "df.to_csv(output_csv_file_path, index=False)\n",
    "\n",
    "print(\"New column added and CSV file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to add 1 in 'Delta Scuti' column of 'AllStars' if it has a 1 in the 'Delta Scuti' column in other folders\n",
    "import pandas as pd\n",
    "\n",
    "def update_delta_scuti(file1, file2, output_file):\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    if 'Delta Scuti' not in df2.columns:\n",
    "        df2['Delta Scuti'] = 0\n",
    "\n",
    "    for index, row in df1.iterrows():\n",
    "        if row['Delta Scuti'] == 1:\n",
    "            gaiadr2_value = row['StarID']\n",
    "            matching_row_index = df2[df2['GaiaDR2'] == gaiadr2_value].index\n",
    "            if not matching_row_index.empty:\n",
    "                df2.loc[matching_row_index, 'Delta Scuti'] = 1\n",
    "\n",
    "    df2['Delta Scuti'] = df2['Delta Scuti'].fillna(0)\n",
    "    df2['Delta Scuti'] = df2['Delta Scuti'].astype(int)\n",
    "\n",
    "    df2.to_csv(output_file, index=False)\n",
    "    print(f\"Updated CSV file saved as {output_file}\")\n",
    "    \n",
    "file1 = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/qlp200/output_analysis_results_identified.csv\"\n",
    "file2 = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsmain.csv\"\n",
    "output_file = 'updated_file2.csv'\n",
    "\n",
    "update_delta_scuti(file1, file2, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process skewness for all stars in AllStarsmain.csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.stats import skew\n",
    "\n",
    "def calc_lomb_scargle(t, y, fmax):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_metrics(freq, amp, nyquist_frequency):\n",
    "    noise_mask = (freq >= 60) & (freq <= 80)\n",
    "    average_noise = np.mean(amp[noise_mask]) if np.any(noise_mask) else 0\n",
    "    valid_mask = (freq > 5) & (freq <= nyquist_frequency)\n",
    "    freq_valid = freq[valid_mask]\n",
    "    amp_valid = amp[valid_mask]\n",
    "    if len(freq_valid) == 0:\n",
    "        return np.nan, np.nan, average_noise\n",
    "    idx_max = np.argmax(amp_valid)\n",
    "    highest_amp = amp_valid[idx_max]\n",
    "    highest_freq = freq_valid[idx_max]\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def calculate_skewness(amp):\n",
    "    amp = amp[np.isfinite(amp)]\n",
    "    if len(amp) > 0:\n",
    "        return skew(amp)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_nyquist_frequency(exposure_time):\n",
    "    return 1 / (2 * exposure_time / 86400)\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsmain.csv\"\n",
    "output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'skewnessnewfile.csv')\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "df['HighestFrequency'] = np.nan\n",
    "df['HighestAmplitude'] = np.nan\n",
    "df['AverageNoise'] = np.nan\n",
    "df['Skewness'] = np.nan\n",
    "\n",
    "columns_to_check = [\n",
    "    '120s Data', '200s Data', '200s QLP Data',\n",
    "    '600s TESS-SPOC Data', '600s QLP Data',\n",
    "    '1800s TESS-SPOC Data', '1800s QLP Data', 'K260 Data'\n",
    "]\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    star_id = row['GaiaDR2']\n",
    "    nyquist_frequency = None\n",
    "\n",
    "    print(f\"Processing star ID {star_id}...\")\n",
    "\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "        search_result = None\n",
    "        exposure_time = None\n",
    "\n",
    "        for col in columns_to_check:\n",
    "            if row[col] == 1.0:\n",
    "                if col == '120s Data':\n",
    "                    exposure_time = 120\n",
    "                    search_result = search_lightcurve(star, mission='TESS', author='SPOC', exptime=120)\n",
    "                elif col == '200s Data':\n",
    "                    exposure_time = 200\n",
    "                    search_result = search_lightcurve(star, mission='TESS', author='TESS-SPOC', exptime=200)\n",
    "                elif col == '200s QLP Data':\n",
    "                    exposure_time = 200\n",
    "                    search_result = search_lightcurve(star, author='QLP', exptime=200)\n",
    "                elif col == '600s TESS-SPOC Data':\n",
    "                    exposure_time = 600\n",
    "                    search_result = search_lightcurve(star, mission='TESS', author='TESS-SPOC', exptime=600)\n",
    "                elif col == '600s QLP Data':\n",
    "                    exposure_time = 600\n",
    "                    search_result = search_lightcurve(star, author='QLP', exptime=600)\n",
    "                elif col == '1800s TESS-SPOC Data':\n",
    "                    exposure_time = 1800\n",
    "                    search_result = search_lightcurve(star, mission='TESS', author='TESS-SPOC', exptime=1800)\n",
    "                elif col == '1800s QLP Data':\n",
    "                    exposure_time = 1800\n",
    "                    search_result = search_lightcurve(star, author='QLP', exptime=1800)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown data column '{col}' for star ID {star_id}\")\n",
    "\n",
    "                for other_col in columns_to_check:\n",
    "                    if other_col != col:\n",
    "                        df.at[idx, other_col] = 0.0\n",
    "\n",
    "                break\n",
    "\n",
    "        if search_result is None:\n",
    "            raise ValueError(f\"No valid data column found for target 'GAIA DR2 {star_id}'\")\n",
    "\n",
    "        lc_collection = search_result.download_all()\n",
    "        if not lc_collection:\n",
    "            raise ValueError(f\"No data found for target 'GAIA DR2 {star_id}'\")\n",
    "        \n",
    "        nyquist_frequency = calculate_nyquist_frequency(exposure_time)\n",
    "    except ValueError as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "        time = lc.time.value\n",
    "        flux = lc.flux.value\n",
    "        freq, amp = calc_lomb_scargle(time, flux, nyquist_frequency)\n",
    "        highest_freq, highest_amp, average_noise = find_metrics(freq, amp, nyquist_frequency)\n",
    "        skewness = calculate_skewness(amp)\n",
    "        \n",
    "        df.at[idx, 'HighestFrequency'] = highest_freq\n",
    "        df.at[idx, 'HighestAmplitude'] = highest_amp\n",
    "        df.at[idx, 'AverageNoise'] = average_noise\n",
    "        df.at[idx, 'Skewness'] = skewness\n",
    "\n",
    "        print(f\"Completed processing for star ID {star_id}. Skewness: {skewness}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create skewness graph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremoved.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['log10(Skewness)'] = np.log10(df['Skewness'].replace(0, np.nan))\n",
    "\n",
    "df_delta_scuti_1 = df[df['Delta Scuti'] == 1]\n",
    "df_delta_scuti_0 = df[df['Delta Scuti'] == 0]\n",
    "\n",
    "bins = np.linspace(df['log10(Skewness)'].min(), df['log10(Skewness)'].max(), 20)\n",
    "\n",
    "hist_delta_scuti_0, bins = np.histogram(df_delta_scuti_0['log10(Skewness)'].dropna(), bins=bins)\n",
    "hist_delta_scuti_1, bins = np.histogram(df_delta_scuti_1['log10(Skewness)'].dropna(), bins=bins)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(bins[:-1], hist_delta_scuti_0, width=np.diff(bins), align='edge', label='Non delta Scuti', color='orange', edgecolor='black')\n",
    "\n",
    "plt.bar(bins[:-1], hist_delta_scuti_1, width=np.diff(bins), align='edge', label='delta Scuti = 1', color='blue', edgecolor='black')\n",
    "\n",
    "plt.xlabel('log10(Skewness)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of log10(Skewness) for Delta Scuti')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 2 separate skewness graphs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR311.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['log10(Skewness)'] = np.log10(df['Skewness'].replace(0, np.nan))\n",
    "\n",
    "print(\"Unique values in 'Delta Scuti' column:\", df['Delta Scuti'].unique())\n",
    "\n",
    "df_delta_scuti_1 = df[df['Delta Scuti'] == 1]\n",
    "df_delta_scuti_0 = df[df['Delta Scuti'] == 0]\n",
    "\n",
    "print(f\"Number of entries with Delta Scuti = 1: {len(df_delta_scuti_1)}\")\n",
    "print(f\"Number of entries with Delta Scuti = 0: {len(df_delta_scuti_0)}\")\n",
    "\n",
    "bins = np.linspace(df['log10(Skewness)'].min(), df['log10(Skewness)'].max(), 20)\n",
    "\n",
    "if len(df_delta_scuti_1) > 0:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(df_delta_scuti_1['log10(Skewness)'].dropna(), bins=bins, alpha=0.7, label='delta Scuti', color='blue')\n",
    "    plt.xlabel(r'$\\log_{10}(\\mathrm{Skewness})$', fontsize=16)\n",
    "    plt.ylabel('Frequency',fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data for Delta Scuti = 1\")\n",
    "\n",
    "if len(df_delta_scuti_0) > 0:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(df_delta_scuti_0['log10(Skewness)'].dropna(), bins=bins, alpha=0.7, label='Non-delta Scuti', color='orange')\n",
    "    plt.xlabel(r'$\\log_{10}(\\mathrm{Skewness})$', fontsize=16)\n",
    "    plt.ylabel('Frequency',fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data for Delta Scuti = 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing errors that meant some entries were not showing as 1 or 0\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsmain.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Delta Scuti'] = df['Delta Scuti'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/updated_skewness.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Updated CSV file saved as {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsmain.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['SNR'] = df['HighestAmplitude'] / df['AverageNoise']\n",
    "\n",
    "df['SNR'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/updated_skewness_with_snr.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Updated CSV file with SNR saved as {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add log10Skewness column (Did this and then ran above code blocks)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsmain.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['log10Skewness'] = np.log10(df['Skewness'].replace(0, np.nan))\n",
    "\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsmainnew.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Updated CSV file with log10Skewness saved as {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SNR vs Skewness plot with gradient for 'Maximum Amplitude'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['SNR'] = df['HighestAmplitude'] / df['AverageNoise']\n",
    "df['SNR'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df['log10Skewness'] = np.log10(df['Skewness'].replace(0, np.nan))\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(df['SNR'], df['Skewness'], c=df['HighestAmplitude'], cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(scatter, label='HighestAmplitude')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR')\n",
    "plt.ylabel('Skewness')\n",
    "plt.title('SNR vs Skewness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['SNR'] = df['HighestAmplitude'] / df['AverageNoise']\n",
    "df['SNR'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "max_amplitude_index = df['HighestAmplitude'].idxmax()\n",
    "\n",
    "df_filtered = df.drop(max_amplitude_index)\n",
    "\n",
    "df_filtered['log10Skewness'] = np.log10(df_filtered['Skewness'].replace(0, np.nan))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(df_filtered['SNR'], df_filtered['Skewness'], c=df_filtered['HighestAmplitude'], cmap='viridis', alpha=0.7)\n",
    "colorbar = plt.colorbar(scatter)\n",
    "colorbar.set_label('Highest Amplitude', fontsize=16) \n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR', fontsize=20) \n",
    "plt.ylabel('Skewness', fontsize=20) \n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As above but gradient on cluster age\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['SNR'] = df['HighestAmplitude'] / df['AverageNoise']\n",
    "df['SNR'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df['log10Skewness'] = np.log10(df['Skewness'].replace(0, np.nan))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(df['SNR'], df['Skewness'], c=df['ClusterAge'], cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(scatter, label='ClusterAge')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR')\n",
    "plt.ylabel('Skewness')\n",
    "plt.title('SNR vs Skewness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Delta Scuti'] = df['Delta Scuti'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "df_delta_scuti = df[df['Delta Scuti'] == 1]\n",
    "\n",
    "df_delta_scuti['log10Period'] = np.log10(df_delta_scuti['Period'].replace(0, np.nan))\n",
    "\n",
    "df_delta_scuti = df_delta_scuti.replace([np.inf, -np.inf], np.nan).dropna(subset=['log10Period', 'AbsMag_dr3'])\n",
    "\n",
    "def model_function(logP, a=-3.01, b=-1.40):\n",
    "    return a * logP + b\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(df_delta_scuti['log10Period'], df_delta_scuti['AbsMag_dr3'], c='blue', label='Delta Scuti = 1', alpha=0.7)\n",
    "\n",
    "logP_values = np.linspace(df_delta_scuti['log10Period'].min(), df_delta_scuti['log10Period'].max(), 500)\n",
    "central_Mg_values = model_function(logP_values)\n",
    "plt.plot(logP_values, central_Mg_values, 'k-', label='Model: $M_g = (-3.01) \\log(P) - (1.40)$')\n",
    "\n",
    "plt.xlabel('log10(Period)')\n",
    "plt.ylabel('AbsMag')\n",
    "plt.title('Zoomed in Scatter Plot of log10(Period) vs AbsMag for Delta Scuti = 1 (Full Range)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('scatter_plot_full_delta_scuti.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(df_delta_scuti['log10Period'], df_delta_scuti['AbsMag_dr3'], c='blue', label='Delta Scuti = 1', alpha=0.7)\n",
    "\n",
    "plt.plot(logP_values, central_Mg_values, 'k-', label='Model: $M_g = (-3.01) \\log(P) - (1.40)$')\n",
    "\n",
    "plt.xlabel('log10(Period)')\n",
    "plt.ylabel('AbsMag')\n",
    "plt.title('Scatter Plot of log10(Period) vs AbsMag for Delta Scuti = 1')\n",
    "plt.ylim(-2, 6)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above but don't plot a star if it doesn't have a Gmag_dr3 entry\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Delta Scuti'] = df['Delta Scuti'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "df_delta_scuti = df[df['Delta Scuti'] == 1]\n",
    "\n",
    "df_delta_scuti['log10Period'] = np.log10(df_delta_scuti['Period'].replace(0, np.nan))\n",
    "\n",
    "df_delta_scuti = df_delta_scuti.replace([np.inf, -np.inf], np.nan).dropna(subset=['log10Period', 'AbsMag_dr3', 'Gmag_dr3', 'Bp_Rp_dr3'])\n",
    "\n",
    "filtered_points = df_delta_scuti[df_delta_scuti['AbsMag_stars']>(-3.01*df_delta_scuti['log10Period']-0.90)]\n",
    "filtered_DR3 = filtered_points['GaiaDR3']\n",
    "filtered_DR3.to_csv('filtered_points.csv', index=False)\n",
    "\n",
    "def model_function(logP, a=-3.01, b=-1.40):\n",
    "    return a * logP + b\n",
    "\n",
    "def model_function2(logP, a=-3.01, b=-0.9):\n",
    "    return a * logP + b\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "scatter = plt.scatter(df_delta_scuti['log10Period'], df_delta_scuti['AbsMag_stars'], \n",
    "                      c=df_delta_scuti['Bp-Rp'], cmap='viridis', alpha=0.7)\n",
    "\n",
    "logP_values = np.linspace(df_delta_scuti['log10Period'].min(), df_delta_scuti['log10Period'].max(), 500)\n",
    "central_Mg_values = model_function(logP_values)\n",
    "plt.plot(logP_values, central_Mg_values, 'k-', label='Model: $M_g = (-3.01) \\log(P) - (1.40)$')\n",
    "\n",
    "central_Mg_values2 = model_function2(logP_values)\n",
    "plt.plot(logP_values, central_Mg_values2, label='Model: $M_g = (-3.01) \\log(P) - (0.90)$')\n",
    "\n",
    "plt.xlabel('log10(Period)')\n",
    "plt.ylabel('AbsMag')\n",
    "plt.title('Zoomed in Scatter Plot of log10(Period) vs AbsMag for Delta Scuti = 1 (Full Range)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Bp-Rp')\n",
    "\n",
    "plt.savefig('scatter_plot_full_delta_scuti.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "scatter = plt.scatter(df_delta_scuti['log10Period'], df_delta_scuti['AbsMag_dr3'], \n",
    "                      c=df_delta_scuti['Bp-Rp'], cmap='viridis', alpha=0.7)\n",
    "\n",
    "plt.plot(logP_values, central_Mg_values, 'k-', label='Model: $M_g = (-3.01) \\log(P) - (1.40)$')\n",
    "\n",
    "plt.xlabel('log10(Period)')\n",
    "plt.ylabel('AbsMag')\n",
    "plt.title('Scatter Plot of log10(Period) vs AbsMag for Delta Scuti = 1')\n",
    "plt.ylim(-2, 6)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Bp-Rp')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As above but wiht age gradient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremoved.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Delta Scuti'] = df['Delta Scuti'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "df_delta_scuti = df[df['Delta Scuti'] == 1]\n",
    "\n",
    "df_delta_scuti['log10Period'] = np.log10(df_delta_scuti['Period'].replace(0, np.nan))\n",
    "\n",
    "df_delta_scuti = df_delta_scuti.replace([np.inf, -np.inf], np.nan).dropna(subset=['log10Period', 'AbsMag'])\n",
    "\n",
    "def model_function(logP, a=-3.01, b=-1.40):\n",
    "    return a * logP + b\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "scatter = plt.scatter(df_delta_scuti['log10Period'], df_delta_scuti['AbsMag'], c=df_delta_scuti['ClusterAge'], cmap='viridis', alpha=0.7)\n",
    "\n",
    "logP_values = np.linspace(df_delta_scuti['log10Period'].min(), df_delta_scuti['log10Period'].max(), 500)\n",
    "central_Mg_values = model_function(logP_values)\n",
    "plt.plot(logP_values, central_Mg_values, 'k-', label='Model: $M_g = (-3.01) \\log(P) - (1.40)$')\n",
    "\n",
    "plt.colorbar(scatter, label='ClusterAge')\n",
    "\n",
    "plt.xlabel('log10(Period)')\n",
    "plt.ylabel('AbsMag')\n",
    "plt.title('Scatter Plot of log10(Period) vs AbsMag for Delta Scuti = 1 (Full Range)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('scatter_plot_full_delta_scuti_cluster_age.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "scatter = plt.scatter(df_delta_scuti['log10Period'], df_delta_scuti['AbsMag'], c=df_delta_scuti['ClusterAge'], cmap='viridis', alpha=0.7)\n",
    "\n",
    "plt.plot(logP_values, central_Mg_values, 'k-', label='Model: $M_g = (-3.01) \\log(P) - (1.40)$')\n",
    "\n",
    "plt.colorbar(scatter, label='ClusterAge')\n",
    "\n",
    "plt.xlabel('log10(Period)')\n",
    "plt.ylabel('AbsMag')\n",
    "plt.title('Zoomed-in Scatter Plot of log10(Period) vs AbsMag for Delta Scuti = 1')\n",
    "plt.ylim(-2, 6)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('scatter_plot_zoomed_delta_scuti_cluster_age.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As above, but discretised colour\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Delta Scuti'] = df['Delta Scuti'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "df_delta_scuti = df[df['Delta Scuti'] == 1]\n",
    "\n",
    "df_delta_scuti['log10Period'] = np.log10(df_delta_scuti['Period'].replace(0, np.nan))\n",
    "\n",
    "df_delta_scuti = df_delta_scuti.replace([np.inf, -np.inf], np.nan).dropna(subset=['log10Period', 'AbsMag_stars', 'ClusterAge'])\n",
    "\n",
    "df_delta_scuti = df_delta_scuti.sort_values('ClusterAge')\n",
    "\n",
    "clusters = df_delta_scuti['Cluster'].unique()\n",
    "num_clusters = len(clusters)\n",
    "cmap = plt.get_cmap('viridis', num_clusters)\n",
    "colors = cmap(range(num_clusters))\n",
    "\n",
    "cluster_color_map = {cluster: colors[i] for i, cluster in enumerate(clusters)}\n",
    "df_delta_scuti['color'] = df_delta_scuti['Cluster'].map(cluster_color_map)\n",
    "\n",
    "def model_function(logP, a=-3.01, b=-1.40):\n",
    "    return a * logP + b\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_data = df_delta_scuti[df_delta_scuti['Cluster'] == cluster]\n",
    "    cluster_label = cluster.replace('_', ' ')\n",
    "    plt.scatter(cluster_data['log10Period'], cluster_data['AbsMag_stars'], color=cluster_color_map[cluster], label=f'{cluster_label} (Age: {cluster_data[\"ClusterAge\"].iloc[0]} MYr)', alpha=0.7)\n",
    "\n",
    "logP_values = np.linspace(df_delta_scuti['log10Period'].min(), df_delta_scuti['log10Period'].max(), 500)\n",
    "central_Mg_values = model_function(logP_values)\n",
    "plt.plot(logP_values, central_Mg_values, 'k-', label='Model: $M_g = (-3.01) \\log(P) - (1.40)$')\n",
    "\n",
    "plt.xlabel('log10(Period)')\n",
    "plt.ylabel('AbsMag')\n",
    "plt.title('Scatter Plot of log10(Period) vs AbsMag for Delta Scuti = 1 (Full Range)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_data = df_delta_scuti[df_delta_scuti['Cluster'] == cluster]\n",
    "    cluster_label = cluster.replace('_', ' ')\n",
    "    plt.scatter(cluster_data['log10Period'], cluster_data['AbsMag_stars'], color=cluster_color_map[cluster], label=f'{cluster_label} (Age: {cluster_data[\"ClusterAge\"].iloc[0]} MYr)', alpha=0.7)\n",
    "\n",
    "plt.plot(logP_values, central_Mg_values, 'k-', label='Model: $M_g = (-3.01) \\log(P) - (1.40)$')\n",
    "\n",
    "plt.xlabel(r'$log_{10}$(Period)', fontsize=18)\n",
    "plt.ylabel('Absolute Magnitude', fontsize=18)\n",
    "plt.ylim(-0.5, 4)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.5, 1), prop={'size': 12})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Delta Scuti'] = df['Delta Scuti'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "df_delta_scuti = df[df['Delta Scuti'] == 1]\n",
    "\n",
    "df_delta_scuti = df_delta_scuti[df_delta_scuti['Cluster'] != 'NGC_3532']\n",
    "\n",
    "df_delta_scuti['Cluster'] = df_delta_scuti['Cluster'].replace({\n",
    "    'Melotte_20': 'Alpha Persei',\n",
    "    'Melotte_22': 'Pleiades'\n",
    "}).str.replace('_', ' ')\n",
    "\n",
    "df_delta_scuti['log10Period'] = np.log10(df_delta_scuti['Period'].replace(0, np.nan))\n",
    "\n",
    "df_delta_scuti = df_delta_scuti.replace([np.inf, -np.inf], np.nan).dropna(subset=['log10Period', 'AbsMag_dr3', 'ClusterAge'])\n",
    "\n",
    "df_delta_scuti = df_delta_scuti.sort_values('ClusterAge')\n",
    "\n",
    "clusters = df_delta_scuti['Cluster'].unique()\n",
    "num_clusters = len(clusters)\n",
    "cmap = plt.get_cmap('viridis', num_clusters)\n",
    "colors = cmap(range(num_clusters))\n",
    "\n",
    "cluster_color_map = {cluster: colors[i] for i, cluster in enumerate(clusters)}\n",
    "df_delta_scuti['color'] = df_delta_scuti['Cluster'].map(cluster_color_map)\n",
    "\n",
    "def model_function(logP, a=-3.01, b=-1.40):\n",
    "    return a * logP + b\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_data = df_delta_scuti[df_delta_scuti['Cluster'] == cluster]\n",
    "    plt.scatter(cluster_data['log10Period'], cluster_data['AbsMag_dr3'], color=cluster_color_map[cluster], label=f'{cluster} (Age: {cluster_data[\"ClusterAge\"].iloc[0]} MYr)', alpha=0.7)\n",
    "\n",
    "logP_values = np.linspace(df_delta_scuti['log10Period'].min(), df_delta_scuti['log10Period'].max(), 500)\n",
    "central_Mg_values = model_function(logP_values)\n",
    "plt.plot(logP_values, central_Mg_values, 'k-', label='Model: $M_g = (-3.01) \\log(P) - (1.40)$')\n",
    "\n",
    "plt.xlabel('log10(Period)', fontsize=18)\n",
    "plt.ylabel('AbsMag', fontsize=18)\n",
    "plt.title('Period-Luminosity Relation')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "\n",
    "plt.savefig('scatter_plot_full_delta_scuti_discrete.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_data = df_delta_scuti[df_delta_scuti['Cluster'] == cluster]\n",
    "    plt.scatter(cluster_data['log10Period'], cluster_data['AbsMag_dr3'], color=cluster_color_map[cluster], label=f'{cluster} (Age: {cluster_data[\"ClusterAge\"].iloc[0]} MYr)', alpha=0.7)\n",
    "\n",
    "plt.plot(logP_values, central_Mg_values, 'k-', label='Model: $M_g = (-3.01) \\log(P) - (1.40)$')\n",
    "\n",
    "plt.xlabel(r'$\\log_{10}(\\mathrm{Period})$', fontsize=18)\n",
    "plt.ylabel('Absolute Magnitude', fontsize=18)\n",
    "plt.ylim(-0.5, 4)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "\n",
    "plt.savefig('scatter_plot_zoomed_delta_scuti_discrete.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of apparent magnitude with pulsating fraction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "bins = np.linspace(df['Gmag_dr3'].min(), df['Gmag_dr3'].max(), 20)\n",
    "\n",
    "all_stars_hist, bins = np.histogram(df['Gmag_dr3'].dropna(), bins=bins)\n",
    "delta_scuti_hist, _ = np.histogram(df[df['Delta Scuti'] == 1]['Gmag_dr3'].dropna(), bins=bins)\n",
    "\n",
    "fraction = delta_scuti_hist / all_stars_hist\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax1.hist(df['Gmag_dr3'].dropna(), bins=bins, alpha=0.7, label='All Stars', color='orange')\n",
    "ax1.hist(df[df['Delta Scuti'] == 1]['Gmag_dr3'].dropna(), bins=bins, alpha=0.7, label='Delta Scuti = 1', color='blue')\n",
    "ax1.set_xlabel('Gmag_dr3')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Gmag Histogram with Pulsating Fraction')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "step_x = np.repeat(bins, 2)[1:-1]\n",
    "step_y = np.repeat(fraction, 2)\n",
    "ax2.plot(step_x, step_y, 'k--', label='Pulsating Fraction')\n",
    "ax2.set_ylabel('Fraction of Delta Scuti')\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax1.hist(df['Gmag_dr3'].dropna(), bins=bins, alpha=0.7, label='All Stars', color='orange')\n",
    "ax1.hist(df[df['Delta Scuti'] == 1]['Gmag_dr3'].dropna(), bins=bins, alpha=0.7, label='Delta Scuti = 1', color='blue')\n",
    "ax1.set_xlabel('Gmag_dr3')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Gmag Histogram with Pulsating Fraction')\n",
    "ax1.set_xlim(0, 14)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(step_x, step_y, 'k--', label='Pulsating Fraction')\n",
    "ax2.set_ylabel('Fraction of Delta Scuti')\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR311.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "bins = np.linspace(df['Gmag_dr3'].min(), df['Gmag_dr3'].max(), 40)\n",
    "\n",
    "filtered_stars = df[(df['Bp_Rp_dr3'] >= 0.10) & (df['Bp_Rp_dr3'] <= 0.55)]\n",
    "filtered_stars_hist, bins = np.histogram(filtered_stars['Gmag_dr3'].dropna(), bins=bins)\n",
    "filtered_delta_scuti_hist, _ = np.histogram(filtered_stars[filtered_stars['Delta Scuti'] == 1]['Gmag_dr3'].dropna(), bins=bins)\n",
    "\n",
    "fraction = filtered_delta_scuti_hist / filtered_stars_hist\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "ax1.hist(df['Gmag_dr3'].dropna(), bins=bins, alpha=0.5, label='All Stars', color='gray')\n",
    "ax1.hist(filtered_stars['Gmag_dr3'].dropna(), bins=bins, alpha=0.7, label='Filtered Stars (0.10 <= Bp_Rp_dr3 <= 0.55)', color='darkorange')\n",
    "ax1.hist(df[df['Delta Scuti'] == 1]['Gmag_dr3'].dropna(), bins=bins, alpha=1.0, label='Delta Scuti = 1', color='blue')\n",
    "\n",
    "ax1.set_xlabel(r'G$_{\\mathrm{mag}}$', fontsize=16)\n",
    "ax1.set_ylabel('Frequency', fontsize=16)\n",
    "ax1.set_title('Gmag Histogram with Pulsating Fraction for Filtered Stars', fontsize=18)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "step_x = np.repeat(bins, 2)[1:-1]\n",
    "step_y = np.repeat(fraction, 2)\n",
    "\n",
    "ax2.plot(step_x, step_y, 'k--', label='Pulsating Fraction for Filtered Stars')\n",
    "ax2.set_ylabel('Fraction of Delta Scuti', fontsize=16)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "ax1.legend(loc='upper left', fontsize=16)\n",
    "ax2.legend(loc='upper right', fontsize=16)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "ax1.hist(df['Gmag_dr3'].dropna(), bins=bins, alpha=0.5, label='All Stars', color='gray')\n",
    "ax1.hist(filtered_stars['Gmag_dr3'].dropna(), bins=bins, alpha=0.7, label='Stars within Instability Strip', color='darkorange')\n",
    "ax1.hist(df[df['Delta Scuti'] == 1]['Gmag_dr3'].dropna(), bins=bins, alpha=1.0, label=r'$\\delta$ Scuti', color='blue')\n",
    "\n",
    "ax1.set_xlabel(r'G$_{\\mathrm{mag}}$', fontsize=25)\n",
    "ax1.set_ylabel('Frequency', fontsize=25)\n",
    "ax1.set_xlim(3, 14)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(step_x, step_y, 'k--', label='Pulsating Fraction')\n",
    "ax2.set_ylabel('Fraction of $\\delta$ Scuti', fontsize=25)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "ax1.legend(loc='upper left', fontsize=20)\n",
    "ax2.legend(loc='upper left', bbox_to_anchor=(0, 0.78), fontsize=20)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR311.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "bins = np.linspace(df['Gmag_dr3'].min(), df['Gmag_dr3'].max(), 40)\n",
    "\n",
    "filtered_stars = df[(df['Bp_Rp_dr3'] >= 0.10) & (df['Bp_Rp_dr3'] <= 0.55)]\n",
    "\n",
    "filtered_hist, _ = np.histogram(filtered_stars['Gmag_dr3'], bins=bins)\n",
    "delta_scuti_hist, _ = np.histogram(filtered_stars[filtered_stars['Delta Scuti'] == 1]['Gmag_dr3'], bins=bins)\n",
    "\n",
    "fraction = np.zeros_like(filtered_hist, dtype=float)\n",
    "fraction[filtered_hist > 0] = delta_scuti_hist[filtered_hist > 0] / filtered_hist[filtered_hist > 0]\n",
    "\n",
    "binomial_error = np.zeros_like(fraction)\n",
    "valid_bins = filtered_hist > 0\n",
    "binomial_error[valid_bins] = np.sqrt(fraction[valid_bins] * (1 - fraction[valid_bins]) / filtered_hist[valid_bins])\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "ax1.hist(df['Gmag_dr3'].dropna(), bins=bins, alpha=0.5, label='All Stars', color='gray')\n",
    "ax1.hist(filtered_stars['Gmag_dr3'].dropna(), bins=bins, alpha=0.7, label='Filtered Stars (0.10 <= Bp_Rp_dr3 <= 0.55)', color='darkorange')\n",
    "ax1.hist(filtered_stars[filtered_stars['Delta Scuti'] == 1]['Gmag_dr3'].dropna(), bins=bins, alpha=1.0, label='Delta Scuti Stars', color='blue')\n",
    "\n",
    "ax1.set_xlabel(r'G$_{\\mathrm{mag}}$', fontsize=16)\n",
    "ax1.set_ylabel('Frequency', fontsize=16)\n",
    "ax1.set_title('Gmag Histogram with Pulsating Fraction for Filtered Stars', fontsize=18)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "step_x = np.repeat(bins, 2)[1:-1]\n",
    "step_y = np.repeat(fraction, 2)\n",
    "\n",
    "ax2.step(bin_centers, fraction, where='mid', linestyle='--', color='k', label='Pulsating Fraction')\n",
    "ax2.errorbar(bin_centers, fraction, yerr=binomial_error, fmt='o', color='black', capsize=5, label='Error Bars')\n",
    "ax2.set_ylabel('Fraction of Delta Scuti Stars', fontsize=16)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "ax1.legend(loc='upper left', fontsize=16)\n",
    "ax2.legend(loc='upper right', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "ax1.hist(df['Gmag_dr3'].dropna(), bins=bins, alpha=0.5, label='All Stars', color='gray')\n",
    "ax1.hist(filtered_stars['Gmag_dr3'].dropna(), bins=bins, alpha=1.0, label='Stars within Instability Strip', color='darkorange')\n",
    "ax1.hist(filtered_stars[filtered_stars['Delta Scuti'] == 1]['Gmag_dr3'].dropna(), bins=bins, alpha=1.0, label=r'$\\delta$ Scuti Stars', color='blue')\n",
    "\n",
    "ax1.set_xlabel(r'G$_{\\mathrm{mag}}$', fontsize=25)\n",
    "ax1.set_ylabel('Number of Stars', fontsize=25)\n",
    "ax1.set_xlim(3, 14)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.step(bin_centers, fraction, where='mid', linestyle='--', color='k', label='Pulsating Fraction')\n",
    "ax2.errorbar(bin_centers, fraction, yerr=binomial_error, fmt='o', color='black', alpha=0.5, capsize=5)\n",
    "ax2.set_ylabel('Fraction of $\\delta$ Scuti Stars', fontsize=25)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "ax1.legend(loc='upper left', fontsize=20)\n",
    "ax2.legend(loc='upper left', bbox_to_anchor=(0, 0.78), fontsize=20)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot of HighestAmplitude vs Gmag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, BoundaryNorm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "num_sectors = df['num sectors'].unique()\n",
    "num_sectors.sort()\n",
    "cmap = plt.cm.plasma\n",
    "norm = BoundaryNorm(num_sectors, cmap.N)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "filled_subset = df[df['Delta Scuti'] == 1]\n",
    "plt.scatter(filled_subset['Gmag_dr3'], np.log10(filled_subset['HighestAmplitude']), c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "hollow_subset = df[df['Delta Scuti'] == 0]\n",
    "colors = cmap(norm(hollow_subset['num sectors']))\n",
    "sc = plt.scatter(hollow_subset['Gmag_dr3'], np.log10(hollow_subset['HighestAmplitude']), facecolors=colors, edgecolors='black', label='Delta Scuti = 0', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), ticks=num_sectors, orientation='vertical')\n",
    "cbar.set_label('Number of Sectors')\n",
    "\n",
    "plt.xlabel('Gmag_dr3')\n",
    "plt.ylabel('log10(HighestAmplitude)')\n",
    "plt.title('Gmag vs log10(HighestAmplitude)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(filled_subset['Gmag_dr3'], np.log10(filled_subset['HighestAmplitude']), c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "sc = plt.scatter(hollow_subset['Gmag_dr3'], np.log10(hollow_subset['HighestAmplitude']), facecolors=colors, edgecolors='black', label='Delta Scuti = 0', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), ticks=num_sectors, orientation='vertical')\n",
    "cbar.set_label('Number of Sectors')\n",
    "\n",
    "plt.xlabel('Gmag_dr3')\n",
    "plt.ylabel('log10(HighestAmplitude)')\n",
    "plt.title('Gmag vs log10(HighestAmplitude)')\n",
    "plt.xlim(4, 14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy of above for presentation diagram\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "num_sectors = df['num sectors'].unique()\n",
    "num_sectors.sort()\n",
    "cmap = plt.cm.plasma\n",
    "norm = BoundaryNorm(num_sectors, cmap.N)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "filled_subset = df[df['Delta Scuti'] == 1]\n",
    "plt.scatter(filled_subset['Gmag_dr3'], np.log10(filled_subset['HighestAmplitude']), c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "hollow_subset = df[df['Delta Scuti'] == 0]\n",
    "colors = cmap(norm(hollow_subset['num sectors']))\n",
    "sc = plt.scatter(hollow_subset['Gmag_dr3'], np.log10(hollow_subset['HighestAmplitude']), facecolors=colors, edgecolors='black', label='Delta Scuti = 0', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), ticks=num_sectors, orientation='vertical')\n",
    "cbar.set_label('Number of Sectors')\n",
    "\n",
    "plt.xlabel('Gmag_dr3')\n",
    "plt.ylabel('log10(HighestAmplitude)')\n",
    "plt.title('Gmag vs log10(HighestAmplitude)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(filled_subset['Gmag_dr3'], np.log10(filled_subset['HighestAmplitude']), c='limegreen', label=r'$\\delta$ Scuti', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "sc = plt.scatter(hollow_subset['Gmag_dr3'], np.log10(hollow_subset['HighestAmplitude']), facecolors=colors, edgecolors='black', label='Non-Delta Scuti', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), ticks=num_sectors, orientation='vertical')\n",
    "cbar.set_label('Number of Sectors', fontsize=16)\n",
    "\n",
    "plt.xlabel(r'G$_{\\mathrm{mag}}$', fontsize=18)\n",
    "plt.ylabel(r'log$_{10}$(Highest Amplitude)', fontsize=18)\n",
    "plt.xlim(4, 14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating above figures but multiplied by factor to reduce scatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "non_zero_num_sectors = df['num sectors'][df['num sectors'] > 0]\n",
    "median_num_sectors = np.median(non_zero_num_sectors)\n",
    "print(\"median\", median_num_sectors)\n",
    "\n",
    "df['MultiplyingFactor'] = np.sqrt(df['num sectors'] / median_num_sectors)\n",
    "df['AdjustedHighestAmplitude'] = df['HighestAmplitude'] * df['MultiplyingFactor']\n",
    "\n",
    "num_sectors = df['num sectors'].unique()\n",
    "num_sectors.sort()\n",
    "cmap = plt.cm.plasma\n",
    "norm = BoundaryNorm(num_sectors, cmap.N)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "filled_subset = df[df['Delta Scuti'] == 1]\n",
    "plt.scatter(filled_subset['Gmag_dr3'], np.log10(filled_subset['AdjustedHighestAmplitude']), c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "hollow_subset = df[df['Delta Scuti'] == 0]\n",
    "colors = cmap(norm(hollow_subset['num sectors']))\n",
    "sc = plt.scatter(hollow_subset['Gmag_dr3'], np.log10(hollow_subset['AdjustedHighestAmplitude']), facecolors=colors, edgecolors='black', label='Delta Scuti = 0', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), ticks=num_sectors, orientation='vertical')\n",
    "cbar.set_label('Number of Sectors')\n",
    "\n",
    "plt.xlabel('Gmag')\n",
    "plt.ylabel('log10(Adjusted Highest Amplitude)')\n",
    "plt.title('Adjusted Gmag vs log10(HighestAmplitude)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(filled_subset['Gmag'], np.log10(filled_subset['AdjustedHighestAmplitude']), c='limegreen', label=r'$\\delta$ Scuti', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "sc = plt.scatter(hollow_subset['Gmag'], np.log10(hollow_subset['AdjustedHighestAmplitude']), facecolors=colors, edgecolors='black', label=r'Non-$\\delta$ Scuti', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), ticks=num_sectors, orientation='vertical')\n",
    "cbar.set_label('Number of Sectors', fontsize=16)\n",
    "\n",
    "plt.xlabel(r'G$_{\\mathrm{mag}}$', fontsize=18)\n",
    "plt.ylabel(r'log$_{10}$(Highest Amplitude)', fontsize=18)\n",
    "plt.xlim(4, 14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As above, but make changes as Tim suggested where I only adjust non-delta scutis' amplitudes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "non_zero_num_sectors = df['num sectors'][df['num sectors'] > 0]\n",
    "median_num_sectors = np.median(non_zero_num_sectors)\n",
    "\n",
    "df['MultiplyingFactor'] = np.sqrt(df['num sectors'] / median_num_sectors)\n",
    "df['AdjustedHighestAmplitude'] = df['HighestAmplitude']\n",
    "df.loc[df['Delta Scuti'] == 0, 'AdjustedHighestAmplitude'] = df['HighestAmplitude'] * df['MultiplyingFactor']\n",
    "\n",
    "num_sectors = df['num sectors'].unique()\n",
    "num_sectors.sort()\n",
    "cmap = plt.cm.plasma\n",
    "norm = BoundaryNorm(num_sectors, cmap.N)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "filled_subset = df[df['Delta Scuti'] == 1]\n",
    "plt.scatter(filled_subset['Gmag_dr3'], np.log10(filled_subset['HighestAmplitude']), c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "hollow_subset = df[df['Delta Scuti'] == 0]\n",
    "colors = cmap(norm(hollow_subset['num sectors']))\n",
    "sc = plt.scatter(hollow_subset['Gmag_dr3'], np.log10(hollow_subset['AdjustedHighestAmplitude']), facecolors=colors, edgecolors='black', label='Delta Scuti = 0', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), ticks=num_sectors, orientation='vertical')\n",
    "cbar.set_label('Number of Sectors')\n",
    "\n",
    "plt.xlabel('Gmag')\n",
    "plt.ylabel('log10(Adjusted Highest Amplitude)')\n",
    "plt.title('Adjusted Gmag vs log10(HighestAmplitude)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(filled_subset['Gmag_dr3'], np.log10(filled_subset['HighestAmplitude']), c='limegreen', label=r'$\\delta$ Scuti', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "sc = plt.scatter(hollow_subset['Gmag_dr3'], np.log10(hollow_subset['AdjustedHighestAmplitude']), facecolors=colors, edgecolors='black', label=r'Non-$\\delta$ Scuti', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), ticks=num_sectors, orientation='vertical')\n",
    "cbar.set_label('Number of Sectors', fontsize=16)\n",
    "\n",
    "plt.xlabel(r'G$_{\\mathrm{mag}}$', fontsize=18)\n",
    "plt.ylabel(r'log$_{10}$(Highest Amplitude)', fontsize=18)\n",
    "plt.xlim(4, 14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "non_zero_num_sectors = df['num sectors'][df['num sectors'] > 0]\n",
    "median_num_sectors = np.median(non_zero_num_sectors)\n",
    "\n",
    "df['MultiplyingFactor'] = np.sqrt(df['num sectors'] / median_num_sectors)\n",
    "\n",
    "df['AdjustedHighestAmplitude'] = df['HighestAmplitude']\n",
    "df.loc[df['Delta Scuti'] == 0, 'AdjustedHighestAmplitude'] = df['HighestAmplitude'] * df['MultiplyingFactor']\n",
    "\n",
    "clusters = df['Cluster'].unique()\n",
    "\n",
    "cmap = plt.get_cmap('tab10', len(clusters))\n",
    "cluster_colors = {cluster: cmap(i) for i, cluster in enumerate(clusters)}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "filled_subset = df[df['Delta Scuti'] == 1]\n",
    "plt.scatter(filled_subset['Gmag_dr3'], np.log10(filled_subset['HighestAmplitude']),\n",
    "            c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "for cluster in clusters:\n",
    "    subset = df[(df['Cluster'] == cluster) & (df['Delta Scuti'] == 0)]\n",
    "    plt.scatter(subset['Gmag_dr3'], np.log10(subset['AdjustedHighestAmplitude']),\n",
    "                c=[cluster_colors[cluster]], label=f'{cluster} (Delta Scuti = 0)', edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "plt.legend(title='Clusters', bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.xlabel('Gmag')\n",
    "plt.ylabel('log10(Adjusted Highest Amplitude)')\n",
    "plt.title('Adjusted Gmag vs log10(Highest Amplitude) for Delta Scuti = 0 (Colored by Cluster)')\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "plt.scatter(filled_subset['Gmag'], np.log10(filled_subset['HighestAmplitude']),\n",
    "            c='fuchsia', label=r'$\\delta$ Scuti', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "for cluster in clusters:\n",
    "    subset = df[(df['Cluster'] == cluster) & (df['Delta Scuti'] == 0)]\n",
    "    plt.scatter(subset['Gmag'], np.log10(subset['AdjustedHighestAmplitude']),\n",
    "                c=[cluster_colors[cluster]], label=f'{cluster}', edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "plt.legend(title='Clusters', bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.xlabel(r'G$_{\\mathrm{mag}}$', fontsize=18)\n",
    "plt.ylabel(r'log$_{10}$(Highest Amplitude)', fontsize=18)\n",
    "plt.xlim(4, 14)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unadjusted plot - with above cluster colouring\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "non_zero_num_sectors = df['num sectors'][df['num sectors'] > 0]\n",
    "median_num_sectors = np.median(non_zero_num_sectors)\n",
    "\n",
    "df['MultiplyingFactor'] = np.sqrt(df['num sectors'] / median_num_sectors)\n",
    "df['AdjustedHighestAmplitude'] = df['HighestAmplitude']\n",
    "df.loc[df['Delta Scuti'] == 0, 'AdjustedHighestAmplitude'] = df['HighestAmplitude'] * df['MultiplyingFactor']\n",
    "\n",
    "clusters = df['Cluster'].unique()\n",
    "cmap = plt.get_cmap('tab10', len(clusters))\n",
    "cluster_colors = {cluster: cmap(i) for i, cluster in enumerate(clusters)}\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "filled_subset = df[df['Delta Scuti'] == 1]\n",
    "plt.scatter(filled_subset['Gmag_dr3'], np.log10(filled_subset['HighestAmplitude']),\n",
    "            c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "for cluster in clusters:\n",
    "    subset = df[(df['Cluster'] == cluster) & (df['Delta Scuti'] == 0)]\n",
    "    plt.scatter(subset['Gmag_dr3'], np.log10(subset['AdjustedHighestAmplitude']),\n",
    "                c=[cluster_colors[cluster]], label=f'{cluster} (Delta Scuti = 0)', edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "plt.legend(title='Clusters', bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.xlabel('Gmag')\n",
    "plt.ylabel('log10(Adjusted Highest Amplitude)')\n",
    "plt.title('Adjusted Gmag vs log10(Highest Amplitude) for Delta Scuti = 0 (Colored by Cluster)')\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.scatter(filled_subset['Gmag'], np.log10(filled_subset['HighestAmplitude']),\n",
    "            c='fuchsia', label=r'$\\delta$ Scuti', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "for cluster in clusters:\n",
    "    subset = df[(df['Cluster'] == cluster) & (df['Delta Scuti'] == 0)]\n",
    "    plt.scatter(subset['Gmag'], np.log10(subset['AdjustedHighestAmplitude']),\n",
    "                c=[cluster_colors[cluster]], label=f'{cluster}', edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "plt.legend(title='Clusters', bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.xlabel(r'G$_{\\mathrm{mag}}$', fontsize=18)\n",
    "plt.ylabel(r'log$_{10}$(Highest Amplitude)', fontsize=18)\n",
    "plt.xlim(4, 14)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As above but with age gradient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "non_zero_num_sectors = df['num sectors'][df['num sectors'] > 0]\n",
    "median_num_sectors = np.median(non_zero_num_sectors)\n",
    "\n",
    "df['MultiplyingFactor'] = np.sqrt(df['num sectors'] / median_num_sectors)\n",
    "\n",
    "df['AdjustedHighestAmplitude'] = df['HighestAmplitude'] * df['MultiplyingFactor']\n",
    "\n",
    "cmap = plt.cm.plasma\n",
    "norm = Normalize(vmin=df['ClusterAge'].min(), vmax=df['ClusterAge'].max())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "filled_subset = df[df['Delta Scuti'] == 1]\n",
    "plt.scatter(filled_subset['Gmag_dr3'], np.log10(filled_subset['AdjustedHighestAmplitude']), c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "hollow_subset = df[df['Delta Scuti'] == 0]\n",
    "colors = cmap(norm(hollow_subset['ClusterAge']))\n",
    "sc = plt.scatter(hollow_subset['Gmag_dr3'], np.log10(hollow_subset['AdjustedHighestAmplitude']), facecolors=colors, edgecolors='black', label='Delta Scuti = 0', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), orientation='vertical')\n",
    "cbar.set_label('Cluster Age')\n",
    "\n",
    "plt.xlabel('Gmag')\n",
    "plt.ylabel('log10(Adjusted Highest Amplitude)')\n",
    "plt.title('Adjusted Gmag vs log10(Highest Amplitude)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(filled_subset['Gmag_dr3'], np.log10(filled_subset['AdjustedHighestAmplitude']), c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "sc = plt.scatter(hollow_subset['Gmag_dr3'], np.log10(hollow_subset['AdjustedHighestAmplitude']), facecolors=colors, edgecolors='black', label='Delta Scuti = 0', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), orientation='vertical')\n",
    "cbar.set_label('Cluster Age')\n",
    "\n",
    "plt.xlabel('Gmag')\n",
    "plt.ylabel('log10(Adjusted Highest Amplitude)')\n",
    "plt.title('Adjusted Gmag vs log10(Highest Amplitude)')\n",
    "plt.xlim(4, 14)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot of HighestAmplitude vs Bp-Rp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, BoundaryNorm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "num_sectors = df['num sectors'].unique()\n",
    "num_sectors.sort()\n",
    "cmap = plt.cm.plasma\n",
    "norm = BoundaryNorm(num_sectors, cmap.N)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "filled_subset = df[df['Delta Scuti'] == 1]\n",
    "plt.scatter(filled_subset['Bp_Rp_dr3'], np.log10(filled_subset['HighestAmplitude']), c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "hollow_subset = df[df['Delta Scuti'] == 0]\n",
    "colors = cmap(norm(hollow_subset['num sectors']))\n",
    "sc = plt.scatter(hollow_subset['Bp_Rp_dr3'], np.log10(hollow_subset['HighestAmplitude']), facecolors=colors, edgecolors='black', label='Delta Scuti = 0', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), ticks=num_sectors, orientation='vertical')\n",
    "cbar.set_label('Number of Sectors')\n",
    "\n",
    "plt.xlabel('Bp-Rp')\n",
    "plt.ylabel('log10(HighestAmplitude)')\n",
    "plt.title('Bp-Rp vs log10(HighestAmplitude)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(filled_subset['Bp_Rp_dr3'], np.log10(filled_subset['HighestAmplitude']), c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "sc = plt.scatter(hollow_subset['Bp_Rp_dr3'], np.log10(hollow_subset['HighestAmplitude']), facecolors=colors, edgecolors='black', label='Delta Scuti = 0', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), ticks=num_sectors, orientation='vertical')\n",
    "cbar.set_label('Number of Sectors')\n",
    "\n",
    "plt.xlabel('Bp-Rp')\n",
    "plt.ylabel('log10(HighestAmplitude)')\n",
    "plt.title('Bp-Rp vs log10(HighestAmplitude)')\n",
    "plt.xlim(df['Bp-Rp'].min(), df['Bp-Rp'].max())\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As above but clusterage gradient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "if 'ClusterAge' not in df.columns:\n",
    "    raise ValueError(\"The column 'ClusterAge' is missing from the DataFrame.\")\n",
    "\n",
    "cmap = plt.cm.plasma\n",
    "norm = Normalize(vmin=df['ClusterAge'].min(), vmax=df['ClusterAge'].max())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "filled_subset = df[df['Delta Scuti'] == 1]\n",
    "plt.scatter(filled_subset['Bp_Rp_dr3'], np.log10(filled_subset['HighestAmplitude']), c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "hollow_subset = df[df['Delta Scuti'] == 0]\n",
    "colors = cmap(norm(hollow_subset['ClusterAge']))\n",
    "sc = plt.scatter(hollow_subset['Bp_Rp_dr3'], np.log10(hollow_subset['HighestAmplitude']), facecolors=colors, edgecolors='black', label='Delta Scuti = 0', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), orientation='vertical')\n",
    "cbar.set_label('Cluster Age')\n",
    "\n",
    "plt.xlabel('Bp-Rp')\n",
    "plt.ylabel('log10(HighestAmplitude)')\n",
    "plt.title('Bp-Rp vs log10(HighestAmplitude)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(filled_subset['Bp_Rp_dr3'], np.log10(filled_subset['HighestAmplitude']), c='black', label='Delta Scuti = 1', alpha=0.7, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "sc = plt.scatter(hollow_subset['Bp_Rp_dr3'], np.log10(hollow_subset['HighestAmplitude']), facecolors=colors, edgecolors='black', label='Delta Scuti = 0', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), orientation='vertical')\n",
    "cbar.set_label('Cluster Age')\n",
    "\n",
    "plt.xlabel('Bp-Rp')\n",
    "plt.ylabel('log10(HighestAmplitude)')\n",
    "plt.title('Bp-Rp vs log10(HighestAmplitude)')\n",
    "plt.xlim(df['Bp-Rp'].min(), df['Bp-Rp'].max())\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightkurve import search_lightcurve\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.stats import skew\n",
    "\n",
    "def calc_lomb_scargle(t, y, fmax):\n",
    "    oversample = 10\n",
    "    tmax = t.max()\n",
    "    tmin = t.min()\n",
    "    df = 1.0 / (tmax - tmin)\n",
    "    fmin = 0\n",
    "\n",
    "    freq = np.arange(fmin, fmax, df / oversample)\n",
    "    model = LombScargle(t, y)\n",
    "    power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "    fct = np.sqrt(4. / len(t))\n",
    "    amp = np.sqrt(power) * fct * 1000\n",
    "    return freq, amp\n",
    "\n",
    "def find_metrics(freq, amp, exposure_time):\n",
    "    if exposure_time in [120, 200, 1800]:\n",
    "        noise_mask = (freq >= 80) & (freq <= 100)\n",
    "    elif exposure_time == 600:\n",
    "        noise_mask = (freq >= 62) & (freq <= 72)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported exposure time: {exposure_time}\")\n",
    "\n",
    "    noise_amp = amp[noise_mask]\n",
    "    average_noise = np.mean(noise_amp) if np.any(noise_mask) else 0\n",
    "\n",
    "    if average_noise == 0.0:\n",
    "        print(f\"Average noise is 0.0 for exposure time {exposure_time}\")\n",
    "        print(f\"Noise mask: {noise_mask}\")\n",
    "        print(f\"Noise amplitude values: {noise_amp}\")\n",
    "\n",
    "    valid_mask = (freq > 5) & (freq <= 80)\n",
    "    freq_valid = freq[valid_mask]\n",
    "    amp_valid = amp[valid_mask]\n",
    "\n",
    "    if len(freq_valid) == 0:\n",
    "        return np.nan, np.nan, average_noise\n",
    "\n",
    "    idx_max = np.argmax(amp_valid)\n",
    "    highest_amp = amp_valid[idx_max]\n",
    "    highest_freq = freq_valid[idx_max]\n",
    "\n",
    "    return highest_freq, highest_amp, average_noise\n",
    "\n",
    "def calculate_skewness(freq, amp, nyquist_frequency):\n",
    "    valid_mask = (freq > 5) & (freq <= nyquist_frequency)\n",
    "    amp_valid = amp[valid_mask]\n",
    "\n",
    "    amp_valid = amp_valid[np.isfinite(amp_valid)]\n",
    "    if len(amp_valid) > 0:\n",
    "        return skew(amp_valid)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_nyquist_frequency(exposure_time):\n",
    "    return 1 / (2 * exposure_time / 86400)\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStars.csv\"\n",
    "output_csv_path = os.path.join(os.path.dirname(input_csv_path), 'skewnessnewfile.csv')\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "df['HighestFrequency'] = np.nan\n",
    "df['HighestAmplitude'] = np.nan\n",
    "df['AverageNoise'] = np.nan\n",
    "df['Skewness'] = np.nan\n",
    "\n",
    "columns_to_check = [\n",
    "    '120s Data', '200s Data', '200s QLP Data',\n",
    "    '600s TESS-SPOC Data', '600s QLP Data',\n",
    "    '1800s TESS-SPOC Data', '1800s QLP Data'\n",
    "]\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    star_id = row['GaiaDR2']\n",
    "    nyquist_frequency = None\n",
    "\n",
    "    print(f\"Processing star ID {star_id}...\")\n",
    "\n",
    "    try:\n",
    "        star = f'GAIA DR2 {star_id}'\n",
    "        search_result = None\n",
    "        exposure_time = None\n",
    "\n",
    "        for col in columns_to_check:\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "            if row[col] == 1.0:\n",
    "                if col == '120s Data':\n",
    "                    exposure_time = 120\n",
    "                    search_result = search_lightcurve(star, mission='TESS', author='SPOC', exptime=120)\n",
    "                elif col == '200s Data':\n",
    "                    exposure_time = 200\n",
    "                    search_result = search_lightcurve(star, mission='TESS', author='TESS-SPOC', exptime=200)\n",
    "                elif col == '200s QLP Data':\n",
    "                    exposure_time = 200\n",
    "                    search_result = search_lightcurve(star, author='QLP', exptime=200)\n",
    "                elif col == '600s TESS-SPOC Data':\n",
    "                    exposure_time = 600\n",
    "                    search_result = search_lightcurve(star, mission='TESS', author='TESS-SPOC', exptime=600)\n",
    "                elif col == '600s QLP Data':\n",
    "                    exposure_time = 600\n",
    "                    search_result = search_lightcurve(star, author='QLP', exptime=600)\n",
    "                elif col == '1800s TESS-SPOC Data':\n",
    "                    exposure_time = 1800\n",
    "                    search_result = search_lightcurve(star, mission='TESS', author='TESS-SPOC', exptime=1800)\n",
    "                elif col == '1800s QLP Data':\n",
    "                    exposure_time = 1800\n",
    "                    search_result = search_lightcurve(star, author='QLP', exptime=1800)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown data column '{col}' for star ID {star_id}\")\n",
    "\n",
    "                for other_col in columns_to_check:\n",
    "                    if other_col != col:\n",
    "                        df.at[idx, other_col] = 0.0\n",
    "\n",
    "                break\n",
    "\n",
    "        if search_result is None:\n",
    "            raise ValueError(f\"No valid data column found for target 'GAIA DR2 {star_id}'\")\n",
    "\n",
    "        lc_collection = search_result.download_all()\n",
    "        if not lc_collection:\n",
    "            raise ValueError(f\"No data found for target 'GAIA DR2 {star_id}'\")\n",
    "        \n",
    "        nyquist_frequency = calculate_nyquist_frequency(exposure_time)\n",
    "    except ValueError as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        lc = lc_collection.stitch().remove_nans().remove_outliers()\n",
    "        time = lc.time.value\n",
    "        flux = lc.flux.value\n",
    "        freq, amp = calc_lomb_scargle(time, flux, nyquist_frequency)\n",
    "        highest_freq, highest_amp, average_noise = find_metrics(freq, amp, exposure_time)\n",
    "        skewness = calculate_skewness(freq, amp, nyquist_frequency)\n",
    "        \n",
    "        df.at[idx, 'HighestFrequency'] = highest_freq\n",
    "        df.at[idx, 'HighestAmplitude'] = highest_amp\n",
    "        df.at[idx, 'AverageNoise'] = average_noise\n",
    "        df.at[idx, 'Skewness'] = skewness\n",
    "\n",
    "        print(f\"Completed processing for star ID {star_id}. Skewness: {skewness}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {star_id}: {e}\")\n",
    "\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of sectors for each star\n",
    "import pandas as pd\n",
    "from lightkurve import search_lightcurve\n",
    "\n",
    "def get_number_of_sectors(star_id):\n",
    "    search_result = search_lightcurve(f\"GAIA DR2 {star_id}\", mission='TESS')\n",
    "    if len(search_result) == 0:\n",
    "        return 0\n",
    "    sectors = search_result.table['sequence_number']\n",
    "    unique_sectors = set(sectors)\n",
    "    return len(unique_sectors)\n",
    "\n",
    "input_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew.csv\"\n",
    "output_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnewsectors.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_path)\n",
    "df['num sectors'] = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    star_id = row['GaiaDR2']\n",
    "    num_sectors = get_number_of_sectors(star_id)\n",
    "    df.at[idx, 'num sectors'] = num_sectors\n",
    "    print(f\"Processed star ID {star_id}: observed in {num_sectors} sectors\")\n",
    "\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(\"Analysis complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column for Close/Eclipsing Binary in main csv\n",
    "import pandas as pd\n",
    "\n",
    "first_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/qlp1800/output_analysis_results_identified.csv\"\n",
    "second_csv_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew.csv\"\n",
    "\n",
    "first_df = pd.read_csv(first_csv_path)\n",
    "second_df = pd.read_csv(second_csv_path)\n",
    "\n",
    "if 'Close/eclipsing binary' not in second_df.columns:\n",
    "    second_df['Close/eclipsing binary'] = pd.NA\n",
    "\n",
    "for idx, row in first_df.iterrows():\n",
    "    binary_value = row['Close/eclipsing binary']\n",
    "    \n",
    "    if pd.notna(binary_value):\n",
    "        gaia_id = row['StarID']\n",
    "        matching_rows = second_df[second_df['GaiaDR2'] == gaia_id]\n",
    "        \n",
    "        if not matching_rows.empty:\n",
    "            for match_idx in matching_rows.index:\n",
    "                if pd.isna(second_df.at[match_idx, 'Close/eclipsing binary']):\n",
    "                    second_df.at[match_idx, 'Close/eclipsing binary'] = binary_value\n",
    "                    print(f\"Updated GaiaDR2 {gaia_id} with Close/eclipsing binary value {binary_value}\")\n",
    "\n",
    "second_df.to_csv(second_csv_path, index=False)\n",
    "\n",
    "print(\"Update complete. The second CSV file has been modified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremoved.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "cluster_age_mapping = {\n",
    "    \"Melotte_20\": 98,\n",
    "    \"NGC_2632\": 600,\n",
    "    \"IC_2602\": 46,\n",
    "    \"IC_2391\": 53,\n",
    "    \"Melotte_22\": 135,\n",
    "    \"Collinder_359\": 100,\n",
    "    \"IC_348\": 4,\n",
    "    \"IC_4665\": 55,\n",
    "    \"IC_4756\": 800,\n",
    "    \"Blanco_1\": 150,\n",
    "    \"Collinder_135\": 40,\n",
    "    \"Collinder_140\": 20,\n",
    "    \"NGC_752\": 1460,\n",
    "    \"NGC_2516\": 150,\n",
    "    \"NGC_3532\": 300,\n",
    "    \"NGC_6475\": 195,\n",
    "    \"NGC_6633\": 500,\n",
    "    \"NGC_7092\": 200,\n",
    "    \"Trumpler_10\": 45.5,\n",
    "    \"NGC_2451A\": 65,\n",
    "    \"NGC_2232\": 38\n",
    "}\n",
    "\n",
    "df['ClusterAge'] = df['Cluster'].map(cluster_age_mapping)\n",
    "\n",
    "df.to_csv(\"updated_csv_file.csv\", index=False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to convert GAIADR2 to GAIADR3 in csv file\n",
    "\n",
    "import pandas as pd\n",
    "from astroquery.gaia import Gaia\n",
    "\n",
    "file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremoved.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['GaiaDR3'] = None\n",
    "\n",
    "def get_gaia_dr3_id(dr2_id):\n",
    "    query = f\"\"\"\n",
    "    SELECT dr3.source_id AS dr3_source_id\n",
    "    FROM gaiadr3.gaia_source AS dr3\n",
    "    JOIN gaiadr2.gaia_source AS dr2\n",
    "    ON dr3.dr2_neighbourhood_source_id = dr2.source_id\n",
    "    WHERE dr2.source_id = {dr2_id}\n",
    "    \"\"\"\n",
    "    job = Gaia.launch_job(query)\n",
    "    results = job.get_results()\n",
    "    if 'dr3_source_id' in results.colnames and len(results) > 0:\n",
    "        return results['dr3_source_id'][0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    dr2_id = row['GaiaDR2']\n",
    "    dr3_id = get_gaia_dr3_id(dr2_id)\n",
    "    df.at[index, 'GaiaDR3'] = dr3_id\n",
    "\n",
    "output_file = 'updated_with_gaia_dr3.csv' \n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated CSV saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert GAIA DR2 to DR3 - add new column\n",
    "import pandas as pd\n",
    "from astroquery.gaia import Gaia\n",
    "\n",
    "file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremoved.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['GaiaDR3'] = None\n",
    "\n",
    "def get_gaia_dr3_id(dr2_id):\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "        SELECT dr3_source_id\n",
    "        FROM gaiadr3.dr2_neighbourhood\n",
    "        WHERE dr2_source_id = {dr2_id}\n",
    "        \"\"\"\n",
    "        job = Gaia.launch_job(query)\n",
    "        results = job.get_results()\n",
    "        if len(results) > 0 and 'dr3_source_id' in results.colnames:\n",
    "            return results['dr3_source_id'][0]\n",
    "        else:\n",
    "            print(f\"No DR3 ID found for DR2 ID {dr2_id}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing DR2 ID {dr2_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "dr3_ids = []\n",
    "for index, dr2_id in enumerate(df['GaiaDR2']):\n",
    "    print(f\"Processing {index + 1}/{len(df)}: DR2 ID {dr2_id}...\")\n",
    "    dr3_id = get_gaia_dr3_id(dr2_id)\n",
    "    dr3_ids.append(dr3_id)\n",
    "\n",
    "df['GaiaDR3'] = dr3_ids\n",
    "\n",
    "output_file = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremoved22.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated CSV saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from astroquery.gaia import Gaia\n",
    "\n",
    "file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremoved22.csv\"\n",
    "\n",
    "dr3_ids = df['GaiaDR3'].tolist()\n",
    "\n",
    "def query_gaia_for_measurements(dr3_ids):\n",
    "    ids_string = ', '.join(map(str, dr3_ids))\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT source_id AS GaiaDR3, ra AS RAdeg_dr3, dec AS DEdeg_dr3, \n",
    "           parallax AS plx_dr3, parallax_error AS e_plx_dr3,\n",
    "           phot_g_mean_mag AS Gmag_dr3, bp_rp AS Bp_Rp_dr3\n",
    "    FROM gaiadr3.gaia_source\n",
    "    WHERE source_id IN ({ids_string})\n",
    "    \"\"\"\n",
    "    \n",
    "    job = Gaia.launch_job(query)\n",
    "    results = job.get_results()\n",
    "    return results.to_pandas()\n",
    "\n",
    "gaia_data = query_gaia_for_measurements(dr3_ids)\n",
    "\n",
    "df = pd.merge(df, gaia_data, on='GaiaDR3', how='left')\n",
    "\n",
    "output_file = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremoved23.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated CSV saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create plots of discrepancy between DR2 and DR3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3.csv')\n",
    "\n",
    "df_plot1 = df.dropna(subset=['plx', 'plx_dr3'])\n",
    "plt.figure()\n",
    "plt.scatter(df_plot1['plx'], df_plot1['plx'] - df_plot1['plx_dr3'])\n",
    "plt.xlabel('Parallax')\n",
    "plt.ylabel('DR2 - DR3 parallax')\n",
    "plt.title('DR2 vs DR3 Parallax')\n",
    "plt.show()\n",
    "\n",
    "df_plot2 = df.dropna(subset=['Gmag', 'Gmag_dr3'])\n",
    "plt.figure()\n",
    "plt.scatter(df_plot2['Gmag'], df_plot2['Gmag'] - df_plot2['Gmag_dr3'])\n",
    "plt.xlabel('Gmag')\n",
    "plt.ylabel('DR2 - DR3 Gmag')\n",
    "plt.title('DR2 vs DR3 Gmag')\n",
    "plt.show()\n",
    "\n",
    "df_plot3 = df.dropna(subset=['Bp-Rp', 'Bp_Rp_dr3'])\n",
    "plt.figure()\n",
    "plt.scatter(df_plot3['Bp-Rp'], df_plot3['Bp-Rp'] - df_plot3['Bp_Rp_dr3'])\n",
    "plt.xlabel('Bp-Rp')\n",
    "plt.ylabel('DR2 - DR3 Bp-Rp')\n",
    "plt.title('DR2 vs DR3 Bp-Rp')\n",
    "plt.show()\n",
    "\n",
    "df_plot4 = df.dropna(subset=['AbsMag', 'AbsMag_dr3'])\n",
    "plt.figure()\n",
    "plt.scatter(df_plot4['AbsMag'], df_plot4['AbsMag'] - df_plot4['AbsMag_dr3'])\n",
    "plt.xlabel('AbsMag')\n",
    "plt.ylabel('DR2 - DR3 AbsMag')\n",
    "plt.title('DR2 vs DR3 AbsMag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add vsini column to spreadsheet - investigate rotation\n",
    "import pandas as pd\n",
    "from astroquery.simbad import Simbad\n",
    "\n",
    "file_path = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['vsini'] = None\n",
    "\n",
    "custom_simbad = Simbad()\n",
    "custom_simbad.add_votable_fields('rot')\n",
    "\n",
    "def fetch_vsini(gaia_dr3_id):\n",
    "    try:\n",
    "        result_table = custom_simbad.query_object(f\"Gaia DR3 {gaia_dr3_id}\")\n",
    "        if result_table is not None and 'rot' in result_table.colnames:\n",
    "            return result_table['rot'][0]\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "vsini_values = []\n",
    "for index, gaia_dr3_id in enumerate(df['GaiaDR3']):\n",
    "    vsini = fetch_vsini(gaia_dr3_id)\n",
    "    vsini_values.append(vsini)\n",
    "\n",
    "df['vsini'] = vsini_values\n",
    "\n",
    "output_file = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3vsini.csv'\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find pulsating fraction\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_path = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR3new.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "clusters = df['Cluster'].unique()\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    total_entries = len(cluster_data)\n",
    "    delta_scuti_count = cluster_data['Delta Scuti'].sum()\n",
    "    \n",
    "    print(f\"Cluster: {cluster}\")\n",
    "    print(f\"  Total entries: {total_entries}\")\n",
    "    print(f\"  Delta Scuti (1): {delta_scuti_count}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path1 = '/Users/tilakpatel/Downloads/AllStarsnew_withstarsremovedDR311(in).csv'  \n",
    "csv_file_path2 = '/Users/tilakpatel/Downloads/AllStarsmain(in).csv'  \n",
    "\n",
    "df1 = pd.read_csv(csv_file_path1)\n",
    "df2 = pd.read_csv(csv_file_path2)\n",
    "\n",
    "cluster_ages = []\n",
    "delta_scuti_fractions = []\n",
    "\n",
    "clusters_df1 = df1.groupby('Cluster')\n",
    "\n",
    "for cluster_name, group in clusters_df1:\n",
    "    cluster_age = group['ClusterAge'].iloc[0]\n",
    "    delta_scuti_count = group[group['Delta Scuti'] == 1].shape[0]\n",
    "    cluster_in_df2 = df2[df2['Cluster'] == cluster_name]\n",
    "    bp_rp_count = cluster_in_df2[(cluster_in_df2['Bp-Rp'] >= 0.10) & (cluster_in_df2['Bp-Rp'] <= 0.55)].shape[0]\n",
    "    \n",
    "    if bp_rp_count == 0:\n",
    "        continue\n",
    "    \n",
    "    delta_scuti_fraction = delta_scuti_count / bp_rp_count\n",
    "    \n",
    "    cluster_ages.append(cluster_age)\n",
    "    delta_scuti_fractions.append(delta_scuti_fraction)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cluster_ages, delta_scuti_fractions, color='blue', label='Delta Scuti Fraction')\n",
    "plt.plot(cluster_ages, delta_scuti_fractions, linestyle='--', color='gray')\n",
    "\n",
    "plt.title('Fraction of Delta Scuti Stars vs Cluster Age')\n",
    "plt.xlabel('Cluster Age (in appropriate units)')\n",
    "plt.ylabel('Fraction of Delta Scuti Stars (Delta Scuti = 1 / Total Stars in Bp-Rp range)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "base_output_directory = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AmplitudeSpectra'\n",
    "plot_output_directory = '/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/ClusterPlots'\n",
    "\n",
    "def read_cluster_data(cluster_folder):\n",
    "    data = []\n",
    "    for filename in os.listdir(cluster_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(cluster_folder, filename)\n",
    "\n",
    "            if os.stat(file_path).st_size == 0:\n",
    "                print(f\"Skipping empty file: {filename}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                star_info = filename.replace('.csv', '').split()\n",
    "                \n",
    "                if len(star_info) == 2:\n",
    "                    star_name = star_info[0]\n",
    "                    star_color = float(star_info[1])\n",
    "                    author = \"Unknown\"\n",
    "                    mission = \"Unknown\"\n",
    "                    exposure_time = \"Unknown\"\n",
    "                \n",
    "                elif len(star_info) == 5:\n",
    "                    star_name = star_info[0]\n",
    "                    author = star_info[1]\n",
    "                    mission = star_info[2]\n",
    "                    exposure_time = star_info[3]\n",
    "                    star_color = float(star_info[4])\n",
    "                \n",
    "                else:\n",
    "                    print(f\"Skipping file {filename}: unexpected filename format\")\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_csv(file_path)\n",
    "                df_after_5 = df[df['Frequency'] > 5]\n",
    "                if len(df_after_5) > 0:\n",
    "                    df['Amplitude'] /= df_after_5['Amplitude'].max()\n",
    "                    data.append((df, star_name, round(star_color, 2), author, mission, exposure_time))\n",
    "                else:\n",
    "                    print(f\"Skipping star {star_name} due to insufficient data after frequency > 5\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing {filename}: {e}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_stacked_plot(cluster_name, data, cluster_folder):\n",
    "    if cluster_name == \"Melotte_20\":\n",
    "        cluster_display_name = \"Alpha Persei\"\n",
    "    elif cluster_name == \"Melotte_22\":\n",
    "        cluster_display_name = \"Pleiades\"\n",
    "    else:\n",
    "        cluster_display_name = cluster_name.replace('_', ' ')\n",
    "\n",
    "    data.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 12.2))\n",
    "    nplots = len(data)\n",
    "    ax.set_xlim(5, 100)\n",
    "    ax.set_ylim(0, nplots)\n",
    "    ax.set_xlabel(r\"Frequency (d$^{-1}$)\", fontsize=24)\n",
    "    ax.set_ylabel(r\"Amplitude (normalised)\", fontsize=24)\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "    ax.set_title(f\"{cluster_display_name}\", fontsize=24, pad=20, weight='bold')\n",
    "\n",
    "    offset = 0\n",
    "    for df, star_name, star_color, _, _, _ in data:\n",
    "        freq = df['Frequency'].to_numpy()\n",
    "        amp = df['Amplitude'].to_numpy()\n",
    "\n",
    "        ax.plot(freq, amp + offset, color='black', linewidth=0.5)\n",
    "\n",
    "        right_edge = ax.get_xlim()[1]\n",
    "\n",
    "        annotation = f\"{star_name} ({star_color:.2f})\"\n",
    "        ax.annotate(annotation, xy=(right_edge, offset + 0.4), ha='right', color='k', size=12)\n",
    "\n",
    "        offset += 1\n",
    "\n",
    "    plot_filename = os.path.join(cluster_folder, f\"{cluster_name}.pdf\")\n",
    "    plt.savefig(plot_filename, format='pdf', bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "for cluster_name in os.listdir(base_output_directory):\n",
    "    cluster_folder = os.path.join(base_output_directory, cluster_name)\n",
    "    if os.path.isdir(cluster_folder):\n",
    "        print(f\"Processing cluster: {cluster_name}\")\n",
    "        cluster_data = read_cluster_data(cluster_folder)\n",
    "        create_stacked_plot(cluster_name, cluster_data, cluster_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Produce pulsating fraction plots for each cluster - colour on x-axis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR311.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Cluster'] = df['Cluster'].replace({\n",
    "    'Melotte_22': 'Pleiades',\n",
    "    'Melotte_20': 'Alpha Persei'\n",
    "}).str.replace('_', ' ')\n",
    "\n",
    "clusters = df['Cluster'].unique()\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    \n",
    "    delta_scuti_data = cluster_data[cluster_data['Delta Scuti'] == 1]['Bp_Rp_dr3']\n",
    "    non_delta_scuti_data = cluster_data[cluster_data['Delta Scuti'] == 0]['Bp_Rp_dr3']\n",
    "    \n",
    "    bins = np.arange(0, 0.8 + 0.05, 0.05)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    ax.hist(non_delta_scuti_data, bins=bins, alpha=1, label='non-$\\delta$ Scuti', color='orange')\n",
    "    ax.hist(delta_scuti_data, bins=bins, alpha=1, label=r'$\\delta$ Scuti', color='blue')\n",
    "    \n",
    "    ax.set_xlabel(r'$G_{BP} - G_{RP}$', fontsize=18)\n",
    "    ax.set_ylabel(r'$N$', fontsize=18)\n",
    "    ax.set_title(f'{cluster}', fontsize=18)\n",
    "    \n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    ax.set_xlim(0, 0.7)\n",
    "    \n",
    "    ax.legend(fontsize=16)\n",
    "    \n",
    "    plt.savefig(f'{cluster}_delta_scuti_histogram.png')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR311.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Cluster'] = df['Cluster'].replace({\n",
    "    'Melotte_22': 'Pleiades',\n",
    "    'Melotte_20': 'Alpha Persei'\n",
    "}).str.replace('_', ' ')\n",
    "\n",
    "exclude_clusters = ['NGC 6633', 'IC 4756', 'IC 4665', 'Collinder 359']\n",
    "\n",
    "df = df[~df['Cluster'].isin(exclude_clusters)]\n",
    "\n",
    "delta_scuti_data = df[df['Delta Scuti'] == 1]['Bp_Rp_dr3']\n",
    "non_delta_scuti_data = df[df['Delta Scuti'] == 0]['Bp_Rp_dr3']\n",
    "\n",
    "bins = np.arange(0, 0.8 + 0.05, 0.05)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.hist(non_delta_scuti_data, bins=bins, alpha=1, label='non-$\\delta$ Scuti', color='orange')\n",
    "ax.hist(delta_scuti_data, bins=bins, alpha=1, label=r'$\\delta$ Scuti', color='blue')\n",
    "\n",
    "ax.set_xlabel(r'$G_{BP} - G_{RP}$', fontsize=18)\n",
    "ax.set_ylabel(r'$N$', fontsize=18)\n",
    "ax.set_title('Combined $\\delta$ Scuti and non-$\\delta$ Scuti Stars', fontsize=18)\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_xlim(0, 0.7)\n",
    "ax.legend(fontsize=16)\n",
    "\n",
    "plt.savefig('combined_delta_scuti_histogram.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "csv_file_path = \"/Users/tilakpatel/Library/CloudStorage/OneDrive-TheUniversityofSydney(Students)/Honours Project/Membership Lists/GAIA DR2 - Cantat-Gaudin/AllStarsnew_withstarsremovedDR311.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Cluster'] = df['Cluster'].replace({\n",
    "    'Melotte_22': 'Pleiades',\n",
    "    'Melotte_20': 'Alpha Persei'\n",
    "}).str.replace('_', ' ')\n",
    "\n",
    "clusters_to_remove = ['NGC 6633', 'IC 4756', 'IC 4665', 'Collinder 359']\n",
    "df = df[~df['Cluster'].isin(clusters_to_remove)]\n",
    "\n",
    "table_data = []\n",
    "\n",
    "clusters = df['Cluster'].unique()\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    distance = cluster_data['ClusterDist(pc)'].iloc[0]\n",
    "    age = cluster_data['ClusterAge'].iloc[0]\n",
    "    num_delta_scuti = cluster_data[cluster_data['Delta Scuti'] == 1].shape[0]\n",
    "    total_stars = cluster_data.shape[0]\n",
    "    stars_within_strip = cluster_data[(cluster_data['Bp_Rp_dr3'] >= 0.1) & (cluster_data['Bp_Rp_dr3'] <= 0.55)]\n",
    "    num_stars_in_strip = stars_within_strip.shape[0]\n",
    "    \n",
    "    if num_stars_in_strip > 0:\n",
    "        pulsator_fraction = round(num_delta_scuti / num_stars_in_strip, 2)\n",
    "    else:\n",
    "        pulsator_fraction = 0.00\n",
    "    \n",
    "    table_data.append({\n",
    "        'Cluster Name': cluster,\n",
    "        'Distance (pc)': distance,\n",
    "        'Age (MYr)': age,\n",
    "        ' Scuti Stars': num_delta_scuti,\n",
    "        'Total Stars': total_stars,\n",
    "        'Stars within\\nInstability Strip': num_stars_in_strip,\n",
    "        'Pulsator Fraction': pulsator_fraction\n",
    "    })\n",
    "\n",
    "table_df = pd.DataFrame(table_data)\n",
    "\n",
    "with PdfPages('cluster_delta_scuti_table.pdf') as pdf:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=table_df.values, colLabels=table_df.columns, cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.auto_set_column_width([0, 1, 2, 3, 4, 5, 6])\n",
    "    \n",
    "    for key, cell in table.get_celld().items():\n",
    "        if key[0] == 0:\n",
    "            cell.set_text_props(weight='bold')\n",
    "            cell.set_height(0.1)\n",
    "        if key[1] == 0:\n",
    "            cell.set_text_props(weight='bold')\n",
    "    \n",
    "    pdf.savefig(fig)\n",
    "    plt.close()\n",
    "\n",
    "print(\"Table saved as cluster_delta_scuti_table.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
